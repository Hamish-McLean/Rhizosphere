---
title: "Root endophyte analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(comment = "#")
knitr::opts_chunk$set(fig.width = 9, fig.height = 9)
knitr::opts_chunk$set(error = TRUE)
```

# Setup

## Libraries

```{r libraries}
library(DESeq2)
library(tidyverse)
library(data.table)
library(vegan)
library(lmPerm)
library(viridis)
library(grid)
library(gridExtra)
library(cowplot)
library(iNEXT)

# library(devtools)
# install_github("eastmallingresearch/Metabarcoding_pipeline/scripts")
library(metafuncs)
```

## Functions and constants

```{r constants}
ALPHA =      0.1   # DESeq2 alpha value
OTUFILTER =  0.01  # Remove OTUs with proportion of total reads below value
READFILTER = 0.05  # Will remove samples with read sum below sample_median_reads*READFILTER 
PAIREDONLY = F     # Will remove the pair of samples which fail the readfilter - probably only useful for DESeq separated by type NOTE removes pairs before DESeq object is created   
TAXCONF =    0.60  # Sets the taxonomy confidence level to get "rank" in taxonomy files
TOPOTU =     10    # Number of Top OTUs for summary information
DIFFOTU =    10    # Number of Top OTUs for differential analysis

DNORM =      F     # Boolean for DeSeq2 normalisation

# graphics
DEVICE =     "png"
DPI =        1200
WIDTH =      9
HEIGHT =     9

# Model design
Factor1 = "trial"
Factor2 = "cultivar"
DESIGN = y ~ trial + planting_season + cultivar
```

```{r functions}
# colour blind palette
cbPalette <- c(
  "#000000", "#E69F00", "#56B4E9", "#009E73", 
  "#F0E442", "#0072B2", "#D55E00", "#CC79A7"
)

# source("functions/rarefaction.R")
source("functions/metabarcoding.R")
source("functions/loadme.R")
```

# Load data

Bacterial and fungal ASV (ZOTU) tables, sample metadata, and taxonomy files are
loaded into named lists using the `loadData` function from Greg's `metafuncs` 
package.

```{r data}
metadata <- "sample_metadata.txt"

# Load data
ubiome_BAC <- loadData("data/BAC.zotu_table.txt",metadata,"data/zBAC.sintax.taxa",RHB="BAC")
ubiome_FUN <- loadData("data/FUN.zotu_table.txt",metadata,"data/zFUN.sintax.taxa",RHB="FUN")

# Correct for planting date month variability.
# March and April are replaced by spring, December by winter.
ubiome_BAC$colData <- ubiome_BAC$colData %>%
  mutate(
    planting_season = case_when(
      planting_date %in% c("march", "april") ~ "spring",
      planting_date %in% c("dec") ~ "winter"
    )
  )

ubiome_FUN$colData <- ubiome_FUN$colData %>%
  mutate(
    planting_season = case_when(
      planting_date %in% c("march", "april") ~ "spring",
      planting_date %in% c("dec") ~ "winter"
    )
  )
```

## Global removals

```{r}
# Sample "A2-7" removed due to missampling.
ubiome_BAC$colData <- ubiome_BAC$colData[!rownames(ubiome_BAC$colData) %in% "HMA27", ]
ubiome_BAC$countData <- ubiome_BAC$countData[, !colnames(ubiome_BAC$countData) %in% "HMA27"]
ubiome_FUN$colData <- ubiome_FUN$colData[!rownames(ubiome_FUN$colData) %in% "HMA27", ]
ubiome_FUN$countData <- ubiome_FUN$countData[, !colnames(ubiome_FUN$countData) %in% "HMA27"]
```

# Filter samples and OTUs

## Filtering taxa

Plantae taxa are filtered from fungal `taxData`.
Chloroplast and Eukaryote  taxa are filtered from bacterial `taxData`.
Corresponding OTUs are removed from `countData`.

```{r filter_taxa}
# Filter Plant, Chloroplast, and Eukaryote OTUs

# Fungi: Plantae OTUs
cat("Fungi:", length(grep("Plantae", ubiome_FUN$taxData$kingdom)), "Plantae OTUs\n")

# Bacteria: Chloroplast (Streptophyta) and Eukaryote OTUs
cat(
  "Bacteria:", length(grep("Streptophyta", ubiome_BAC$taxData$genus)), "Chloroplast OTUs;", 
  length(grep("Eukaryota", ubiome_BAC$taxData$kingdom)), "Eukaryote OTUs\n"
)

# Filter Chloroplast and Eukaryote
filt <- rownames(
  ubiome_BAC$taxData[
    grepl("Streptophyta", ubiome_BAC$taxData$genus) & 
    as.numeric(ubiome_BAC$taxData$g_conf) >= TAXCONF,
  ]
)

filt <- c(filt, rownames(ubiome_BAC$taxData[grep("Eukaryota", ubiome_BAC$taxData$kingdom), ]))

cat("Bacteria: removing", length(filt), "OTUs")

ubiome_BAC$taxData <- ubiome_BAC$taxData[!rownames(ubiome_BAC$taxData) %in% filt, ]
ubiome_BAC$countData <- ubiome_BAC$countData[!rownames(ubiome_BAC$countData) %in% filt, ]
```

## Filtering samples

Plot rarefaction curves.

Remove samples with read count below `r READFILTER * 100` % of median.

```{r filter_samples}
invisible(mapply(assign, names(ubiome_BAC), ubiome_BAC, MoreArgs = list(envir = globalenv())))
rare_bac <- gfunc(countData, colData, "Bacteria")
# rare_bac <- gfunc(as.data.frame(counts(dds)), as.data.frame(colData(dds)), "Bacteria ZOTU")
invisible(mapply(assign, names(ubiome_FUN), ubiome_FUN, MoreArgs = list(envir = globalenv())))
rare_fun <- gfunc(countData, colData, "Fungi")
# rare_fun <- gfunc(as.data.frame(counts(dds)), as.data.frame(colData(dds)), "Fungi ZOTU")

rarefaction_plots <- grid.arrange(
  rare_bac, rare_fun,
  left = textGrob(label = expression("log"[10] * " aligned sequenecs"), rot = 90),
  bottom = "ASV count", nrow = 2
)

ggsave(filename = "rarefaction_plots.png", plot = rarefaction_plots, path = "figures/")

rarefaction_plots

# Fungi
med <- median(colSums(ubiome_FUN$countData))
filt <- !colSums(ubiome_FUN$countData) > med * READFILTER
cat("Fungi: ",sum(filt),"sample(s) removed\n")

# Bacteria
med <- median(colSums(ubiome_BAC$countData))
filt <- !colSums(ubiome_BAC$countData) > med * READFILTER
cat("Bacteria: ",sum(filt),"sample(s) removed\n")
```

## Filter reads

Remove OTUs with read count below `r OTUFILTER * 100` % of total reads.

```{r filter_reads}
# Fungi
keep <- filter_otus(ubiome_FUN$countData, OTUFILTER)
cat("Fungi: removing", nrow(ubiome_FUN$countData) - length(keep), "OTUs\n")

ubiome_FUN$taxData <- ubiome_FUN$taxData[rownames(ubiome_FUN$taxData) %in% keep,]
ubiome_FUN$countData <- ubiome_FUN$countData[rownames(ubiome_FUN$countData) %in% keep,]

# Bacteria
keep <-  filter_otus(ubiome_BAC$countData, OTUFILTER)
cat("Bacteria: removing", nrow(ubiome_BAC$countData) - length(keep), "OTUs")

ubiome_BAC$taxData <- ubiome_BAC$taxData[rownames(ubiome_BAC$taxData) %in% keep,]
ubiome_BAC$countData <- ubiome_BAC$countData[rownames(ubiome_BAC$countData) %in% keep,]
```

# Absolute abundance normalisation

OTU normalisation is performed using qPCR theoretical copy number data.
Copy number is calculated per mg of root sample from the qPCR data.

## Prepare qPCR abundance data

```{r abundance}
abundance <- fread("mean_abundance.csv")

# Add sample ID to abundance data
abundance$id <- paste0("HM", gsub("-", "", abundance$Sample))
# abundance$id <- abundance$Sample
abundance$copy_number <- abundance$MeanAdjustedTCN_mg

# Add bacterial (16S) and fungal (ITS) abundance to ubiome BAC and FUN named lists
ubiome_FUN$abundance <- abundance[abundance$Target == "ITS"] %>%
  column_to_rownames(var = "id")
ubiome_BAC$abundance <- abundance[abundance$Target == "16S"] %>%
  column_to_rownames(var = "id")

# Merge copy number from abundance with colData
ubiome_FUN$colData <- merge(
  ubiome_FUN$colData, 
  ubiome_FUN$abundance[, c("Target", "copy_number")], 
  by = 0
) %>% column_to_rownames(var = "Row.names")
ubiome_BAC$colData <- merge(
  ubiome_BAC$colData, 
  ubiome_BAC$abundance[, c("Target", "copy_number")], 
  by = 0
) %>% column_to_rownames(var = "Row.names")
```

### Remove outliers

```{r}
# Detect outliers with std > threshold from the median
detect_outliers <- function(x, val, threshold, na.rm = TRUE) {
  med_x <- median(x[[val]], na.rm = na.rm)
  sd_x <- sd(x[[val]], na.rm = na.rm)
  outliers <- x[x[[val]] > (med_x + threshold * sd_x) | x[[val]] < (med_x - threshold * sd_x), ]
  return(outliers)
}

outliers_FUN <- detect_outliers(ubiome_FUN$abundance, "MeanAdjustedTCN_mg", 3)
outliers_BAC <- detect_outliers(ubiome_BAC$abundance, "MeanAdjustedTCN_mg", 3)

# Remove samples with copy number > 3 std from the median
outliers <- rownames(outliers_FUN)
ubiome_FUN$abundance <- ubiome_FUN$abundance[!rownames(ubiome_FUN$abundance) %in% outliers, ]
ubiome_FUN$countData <- ubiome_FUN$countData[, !colnames(ubiome_FUN$countData) %in% outliers]
ubiome_FUN$colData <- ubiome_FUN$colData[!rownames(ubiome_FUN$colData) %in% outliers, ]

cat("Fungi: removing", length(outliers), "outlier(s)\n")
```

Sample A1-3 is removed from the fungal data due to abnormally high copy number.

# Canker count data

Canker count data for differential expression analysis.

Area under the disease progression curve (AUDPC) is calculated for each tree
using the formula $$\sum_{i=1}^{n-1} \frac{(y_i + y_{i+1})}{2} (x_{i+1} - x_i)$$
where $y_i$ is the canker count at time $x_i$.

```{r}
all_canker_data <- fread("all_canker_data.csv")

# Remove spaces from column names and convert to lowercase
colnames(all_canker_data) <- tolower(gsub(" ", "_", colnames(all_canker_data)))

# Add planting season to canker data and set tree_id and id columns
all_canker_data <- mutate(
  all_canker_data,
  planting_season = case_when(
    planting_date %in% c("March", "April") ~ "spring",
    planting_date %in% c("Dec") ~ "winter"
  ),
  tree_id = id,
  id = substr(tree_id, 1, 4)
)

# Filter canker data to match both id and planting season from colData
all_canker_data <- all_canker_data %>% 
  semi_join(ubiome_BAC$colData, by = c("id", "planting_season"))

# Filter out replacement "7 (GD)" trees
all_canker_data <- all_canker_data[all_canker_data$cultivar_number != "7 (GD)", ]

# Sum mainstem and peripheral canker counts
all_canker_data$mainstem_cankers <- all_canker_data$a4 + all_canker_data$b4
all_canker_data$peripheral_cankers <- all_canker_data$c4 + all_canker_data$d4 + all_canker_data$e4
all_canker_data$total_cankers <- all_canker_data$mainstem_cankers + all_canker_data$peripheral_cankers

# Average mainstem and peripheral canker counts per subplot
canker_data <- all_canker_data %>%
  group_by(id, planting_season, cultivar_number, cultivar) %>%
  summarise(
    mainstem_cankers = mean(mainstem_cankers, na.rm = T),
    peripheral_cankers = mean(peripheral_cankers, na.rm = T),
    total_cankers = mean(total_cankers, na.rm = T)
  )

# Add canker data to colData for both FUN and BAC
ubiome_FUN$colData <- merge(
  rownames_to_column(ubiome_FUN$colData, var = "Row.names"), 
  canker_data[, c("id", "mainstem_cankers", "peripheral_cankers", "total_cankers")], 
  by = "id"
) %>% column_to_rownames("Row.names")

ubiome_BAC$colData <- merge(
  rownames_to_column(ubiome_BAC$colData, var = "Row.names"), 
  canker_data[, c("id", "mainstem_cankers", "peripheral_cankers", "total_cankers")], 
  by = "id"
) %>% column_to_rownames("Row.names")
```

# Create DESeq objects

```{r DESeq}
# Make sure countData and colData still match, if they do, create DESeq objects, if not throw error
if(identical(colnames(ubiome_FUN$countData), rownames(ubiome_FUN$colData))) {
  # Create DESeq object
  ubiome_FUN$dds <- ubiom_to_des(ubiome_FUN)
  print("FUN DESeq object created")
} else {
  stop("FUN countData and colData do not match")
}

if(identical(colnames(ubiome_BAC$countData), rownames(ubiome_BAC$colData))) {
  # Create DESeq object
  ubiome_BAC$dds <- ubiom_to_des(ubiome_BAC)
  print("BAC DESeq object created")
} else {
  stop("BAC countData and colData do not match")
}
```


# Create DESeq objects
ubiome_FUN$dds <- ubiom_to_des(ubiome_FUN)
ubiome_BAC$dds <- ubiom_to_des(ubiome_BAC)
```

# Abundance normalisation

Absolute abundance normalisation using DESeq2 size factors.

Values are centred around the mean of the copy number.

```{r}
# Normalise count data using DESeq2 size factors

ubiome_FUN$dds$sizeFactor <- ubiome_FUN$dds$copy_number / mean(ubiome_FUN$dds$copy_number)
ubiome_BAC$dds$sizeFactor <- ubiome_BAC$dds$copy_number / mean(ubiome_BAC$dds$copy_number)

```

<!-- #=============================================================================== -->
# **Fungi**
<!-- #=============================================================================== -->

```{r}
# Unpack fungi data
invisible(mapply(assign, names(ubiome_FUN), ubiome_FUN, MoreArgs = list(envir = globalenv())))
```

## OTU and sample summary

### Read and sample summary

```{r read_summary}
cat(
  "Raw reads", "\n\n",
  "Total raw reads:\t\t", sum(countData), "\n",
  "Mean raw reads per sample:\t", mean(colSums(countData)), "\n",
  "Median raw reads per sample:\t", median(colSums(countData)), "\n",
  "Max raw reads per sample:\t", max(colSums(countData)), "\n",
  "Min raw reads per sample:\t", min(colSums(countData)), "\n\n"
)
#colSums(countData)

nct <- counts(dds, normalize = T)
cat("Normalised reads", "\n\n",
  "Total normalised reads:\t\t", sum(nct), "\n",
  "Mean normalised reads per sample:\t", mean(colSums(nct)), "\n",
  "Median normalised reads per sample:\t", median(colSums(nct)), "\n",
  "Min normalised reads per sample:\t", min(colSums(nct)), "\n",
  "Max normalised reads per sample:\t", max(colSums(nct)), "\n\n"
)
#round(colSums(counts(dds,normalize = DNORM)),0)
```

### OTU summary 

```{r otu_summary}
cat(
  "Total OTUs:\t\t", nrow(taxData),"\n\n",
  "Raw reads per OTU summary", "\n\n",
  "Mean raw reads per OTU:\t", mean(rowSums(countData)),"\n",
  "Median raw per OTU:\t\t", median(rowSums(countData)),"\n",
  "OTU raw Min reads:\t\t", min(rowSums(countData)),"\n",
  "OTU raw Max reads:\t\t", max(rowSums(countData)),"\n\n"
)

cat(
  "Normalised reads per OTU summary","\n\n",
  "Mean normalised reads per OTU:\t\t", mean(rowSums(nct)),"\n",
  "Median normalised reads per OTU:\t", median(rowSums(nct)),"\n",
  "OTU normalised Min reads:\t\t", min(rowSums(nct)),"\n",
  "OTU normalised Max reads:\t\t", max(rowSums(nct)),"\n\n"
)

y <- rowSums(nct)
y <- y[order(y, decreasing = T)]
# proportion
xy <- y / sum(y)

cat("Top " ,TOPOTU, "OTUs:\n")
data.frame(counts = y[1:TOPOTU], proportion = xy[1:TOPOTU], rank = taxData[names(y)[1:TOPOTU],]$rank)
```

## Taxonomy Summary

### Taxonomy identifiable

Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank.

```{r}

# Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank

tx <- copy(taxData)
setDT(tx)
cols <- names(tx)[9:15]

tx[, (cols) := lapply(.SD, as.factor), .SDcols = cols]

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.8) / nrow(tx))), 2),
  "0.65" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.65) / nrow(tx))), 2),
  "0.5" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.5) / nrow(tx))), 2)
)
```

% of reads which can be assigned to each taxonomic ranks

```{r}

tx <-taxData[rownames(dds),]
nc <- counts(dds, normalize = DNORM)
ac <- sum(nc)

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.8),]) / ac * 100))), 2),
  "0.65" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.65),]) / ac * 100))), 2),
  "0.5" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.5),]) / ac * 100))), 2)
)

```

## Abundance

Plot copy number for each sample grouped by site, cultivar, and planting season.
Test the effect of site, cultivar, and planting season on copy number using ANOVA.

```{r}
abundance_plot <- ggplot(
  data = as.data.frame(colData(dds)), 
  aes(x = trial, y = copy_number, colour = cultivar, shape = planting_season)
) + geom_jitter() + 
  scale_colour_manual(values = cbPalette)

ggsave(
  filename = "fun_abundance.png", plot = abundance_plot, path = "figures/", 
  height = 20, width = 20, units = "cm"
)

abundance_plot

# Formula for ANOVA
formula <- update(DESIGN, copy_number ~ .)

abundance_anova <- aovp(formula, data = as.data.frame(colData(dds)))
summary(abundance_anova)
# abundance_resid <- data.frame(residuals = residuals(abundance_anova))

# norm <- ggplot(abundance_resid, aes(sample = residuals)) + stat_qq() + stat_qq_line()
# ggsave(
#   filename = "fun_abundance_norm.png", plot = norm, path = "figures/", 
#   height = 20, width = 20, units = "cm"
# )
```

# Alpha diversity analysis

## Alpha diversity plot

```{r fun_alpha_diversity}

# plot alpha diversity - plot_alpha will convert normalised abundances to integer values

fun_alpha_plot <- plot_alpha(
  counts(dds, normalize = F), colData(dds),
  design = "cultivar", colour = "trial",
  measures = c("Shannon", "Simpson"),
  type = "box"
) + scale_colour_manual(values = cbPalette) + 
  theme(axis.title.x = element_blank()) +
  ggtitle("Fungal α-diversity") + 
  labs(colour = "Site")
  # facet_wrap(~planting_season)

ggsave(
  filename = "fun_alpha.png", plot = fun_alpha_plot, path = "figures/", 
  height = 20, width = 40, units = "cm"
)

fun_alpha_plot
```

## Permutation based anova on diversity index ranks

```{r}
# get the diversity index data
all_alpha_ord <- plot_alpha(
  counts(dds, normalize = F),
  colData(dds),
  returnData = T
)

# join diversity indices and metadata
all_alpha_ord <- all_alpha_ord[
  as.data.table(colData(dds), keep.rownames = "Samples"), 
  on = "Samples"
]

formula <- DESIGN # x ~ trial * planting_date * cultivar + trial / trial.block
```

### Chao1

```{r}
setkey(all_alpha_ord, S.chao1)
all_alpha_ord[, measure := as.numeric(as.factor(S.chao1))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

### Shannon

```{r}
setkey(all_alpha_ord, shannon)
all_alpha_ord[, measure := as.numeric(as.factor(shannon))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

### Simpson

```{r}
setkey(all_alpha_ord, simpson)
all_alpha_ord[, measure := as.numeric(as.factor(simpson))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

# Beta diversity PCA/NMDS

## PCA

```{r}

# Perform PC decomposition of DES object
mypca <- des_to_pca(dds)

# To get pca plot axis into the same scale create a dataframe of PC scores multiplied by their variance
d <- t(data.frame(t(mypca$x) * mypca$percentVar))

formula = DESIGN
```

### Percent variation in first 4 PCs 

```{r}
round(mypca$percentVar[1:4], 3)
```

### ANOVA of first 4 PCs

```{r} 
apply(
  mypca$x[, 1:4], 2, 
  function(x){
    summary(aov(update(formula, x ~ .), data = as.data.frame(cbind(x, colData(dds)))))
  }
)
```

### PCA plot

```{r, fig.width = 8, fig.height = 5}

pca_plot <- plotOrd(
  d,
  colData(dds),
  design = "cultivar",
  shape = "trial",
  axes = c(1, 2),
  facet = "planting_season", 
  cbPalette = T,
  alpha = 0.75,
) # + facet_wrap(~facet) 
#   geom_line(aes(group=facet),alpha=0.25,linetype=3,colour="#000000") + 
#   theme(text = element_text(size=14))

ggsave(filename = "fun_pca_plot.png", plot = pca_plot, path = "figures/")

pca_plot
```

### PCA sum of squares (% var)

```{r}
sum_squares <- apply(mypca$x, 2 ,function(x) 
  summary(aov(update(formula, x ~ .), data = cbind(x, colData(dds))))[[1]][2]
)
sum_squares <- do.call(cbind, sum_squares)
x <- t(apply(sum_squares, 2, prop.table))
perVar <- x * mypca$percentVar
#colSums(perVar)
round(colSums(perVar) / sum(colSums(perVar)) * 100, 3)
```

## ADONIS

```{r}
vg <- vegdist(t(counts(dds, normalize = DNORM)), method = "bray")
set.seed(sum(utf8ToInt("Hamish McLean")))
adonis2(update(formula, vg ~ .), colData(dds), permutations = 1000)
```

## NMDS ordination

```{r}
set.seed(sum(utf8ToInt("Hamish McLean")))
ord <- metaMDS(vg,trace=0) 
#sratmax=20000,maxit=20000,try = 177, trymax = 177

nmds <- scores(ord)

nmds_plot <- plotOrd(
  nmds, colData(dds), design = Factor2, 
  shape = Factor1, alpha = 0.75, cbPalette = T
) + theme(text = element_text(size = 14))

ggsave(filename = "fun_nmds_plot.png", plot = nmds_plot, path = "figures/")

nmds_plot
```

### NMDS with phylum or class arrows 

```{r} 
otus <- scores(ord, "species") 

taxmerge <- data.table(
  inner_join(
    data.table(OTU = rownames(otus), as.data.frame(otus)),
    data.table(OTU = rownames(taxData), taxData))
) 
taxmerge$phy <- taxaConfVec(
  taxmerge[, c(-1:-3, -8)], conf = 0.9,
  level = which(colnames(taxmerge[, c(-1:-3, -8)]) == "phylum")
)
taxmerge$cls <- taxaConfVec(
  taxmerge[, c(-1:-3, -8)], conf = 0.9,
  level = which(colnames(taxmerge[, c(-1:-3, -8)]) == "class")
) 

phy <- taxmerge[,lapply(.SD,mean),by=phy,.SDcols=c("NMDS1","NMDS2")]
cls <- taxmerge[,lapply(.SD,mean),by=cls,.SDcols=c("NMDS1","NMDS2")]

nmds_plot + geom_segment(
  inherit.aes = F, data = phy, 
  aes(xend = NMDS1, yend = NMDS2, x = 0, y = 0), 
  size = 1.5, arrow = arrow()
) + 
  geom_text(
    inherit.aes = F, data = phy, 
    aes(x = NMDS1, y = (NMDS2 + sign(NMDS2) * 0.05), label = phy)
  )

ggsave(filename = "fun_nmds_phy.png", plot = nmds_plot, path = "figures/")

fun_nmds_plot
```

# Correlation analysis

## Correlation of abundance of top `r DIFFOTU` OTUs with canker count

```{r}
# Extract normalised counts from DESeq object
nc <- counts(dds, normalize = T) %>% as.data.frame()

# Filter the top x abundant OTUs by the sum of their normalised counts
top_otus <- nc[order(rowSums(nc), decreasing = T)[1:DIFFOTU], ]

# Check that sample names match
identical(names(top_otus), rownames(colData))

# Calculate Pearson correlation for each OTU in nc with mainstem canker count for each sample from colData
correlations <- data.frame(
  pearson = apply(top_otus, 1, function(x) cor.test(x, colData$total_cankers, method = "pearson")$estimate),
  p_pearson = apply(top_otus, 1, function(x) cor.test(x, colData$total_cankers, method = "pearson")$p.value),
  spearman = apply(top_otus, 1, function(x) cor.test(x, colData$total_cankers, method = "spearman", exact = F)$estimate),
  p_spearman = apply(top_otus, 1, function(x) cor.test(x, colData$total_cankers, method = "spearman", exact = F)$p.value)
)

# Adjust p-values for multiple testing
correlations$p_pearson_adjusted <- p.adjust(correlations$p_pearson, method = "BH")
correlations$p_spearman_adjusted <- p.adjust(correlations$p_spearman, method = "BH")

# Merge correlations with taxData

```

## Correlation of α-diversity with canker count

```{r}

measures <- c("shannon", "simpson") #, "S.chao1", "S.obs", "S.ACE")
methods <- c("pearson", "spearman")

# Calculate correlations for each α-diversity measure with canker count
alpha_correlations <- data.table(
  measure = rep(measures, each = length(methods)),
  method = rep(methods, times = length(measures)),
  estimate = c(
    sapply(measures, function(x) cor.test(all_alpha_ord[[x]], all_alpha_ord$total_cankers, method = "pearson")$estimate),
    sapply(measures, function(x) cor.test(all_alpha_ord[[x]], all_alpha_ord$total_cankers, method = "spearman", exact = F)$estimate)
  ),
  p_value = c(
    sapply(measures, function(x) cor.test(all_alpha_ord[[x]], all_alpha_ord$total_cankers, method = "pearson")$p.value),
    sapply(measures, function(x) cor.test(all_alpha_ord[[x]], all_alpha_ord$total_cankers, method = "spearman", exact = F)$p.value)
  ),
  p_adjusted = c(
    p.adjust(sapply(measures, function(x) cor.test(all_alpha_ord[[x]], all_alpha_ord$total_cankers, method = "pearson")$p.value), method = "BH"),
    p.adjust(sapply(measures, function(x) cor.test(all_alpha_ord[[x]], all_alpha_ord$total_cankers, method = "spearman", exact = F)$p.value), method = "BH")
  )
)
```

## Correlation of β-diversity PCs with canker count

```{r}

```



<!-- #=============================================================================== -->
# **Bacteria**
<!-- #=============================================================================== -->

```{r}
# Unpack bacteria data
invisible(mapply(assign, names(ubiome_BAC), ubiome_BAC, MoreArgs = list(envir = globalenv())))
```

## OTU and sample summary

### Read and sample summary

```{r}
cat(
  "Raw reads", "\n\n",
  "Total raw reads:\t\t", sum(countData), "\n",
  "Mean raw reads per sample:\t", mean(colSums(countData)), "\n",
  "Median raw reads per sample:\t", median(colSums(countData)), "\n",
  "Max raw reads per sample:\t", max(colSums(countData)), "\n",
  "Min raw reads per sample:\t", min(colSums(countData)), "\n\n"
)
#colSums(countData)

nct <- counts(dds, normalize = T)
cat("Normalised reads", "\n\n",
  "Total normalised reads:\t\t", sum(nct), "\n",
  "Mean normalised reads per sample:\t", mean(colSums(nct)), "\n",
  "Median normalised reads per sample:\t", median(colSums(nct)), "\n",
  "Min normalised reads per sample:\t", min(colSums(nct)), "\n",
  "Max normalised reads per sample:\t", max(colSums(nct)), "\n\n"
)
#round(colSums(counts(dds,normalize = DNORM)),0)
```

### OTU summary 

```{r}
cat(
  "Total OTUs:\t\t", nrow(taxData),"\n\n",
  "Raw reads per OTU summary", "\n\n",
  "Mean raw reads per OTU:\t", mean(rowSums(countData)),"\n",
  "Median raw per OTU:\t\t", median(rowSums(countData)),"\n",
  "OTU raw Min reads:\t\t", min(rowSums(countData)),"\n",
  "OTU raw Max reads:\t\t", max(rowSums(countData)),"\n\n"
)

cat(
  "Normalised reads per OTU summary","\n\n",
  "Mean normalised reads per OTU:\t\t", mean(rowSums(nct)),"\n",
  "Median normalised reads per OTU:\t", median(rowSums(nct)),"\n",
  "OTU normalised Min reads:\t\t", min(rowSums(nct)),"\n",
  "OTU normalised Max reads:\t\t", max(rowSums(nct)),"\n\n"
)

y <- rowSums(nct)
y <- y[order(y, decreasing = T)]
# proportion
xy <- y/sum(y)

cat("Top ", TOPOTU, "OTUs:\n")
data.frame(counts = y[1:TOPOTU], proportion = xy[1:TOPOTU], rank = taxData[names(y)[1:TOPOTU],]$rank)
```

## Taxonomy Summary

### Taxonomy identifiable

Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank

```{r}

# Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank

tx <- copy(taxData)
setDT(tx)
cols <- names(tx)[9:15]

tx[, (cols) := lapply(.SD, as.factor), .SDcols = cols]

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.8) / nrow(tx))), 2),
  "0.65" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.65) / nrow(tx))), 2),
  "0.5" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.5) / nrow(tx))), 2)
)
```

% of reads which can be assigned to each taxonomic ranks

```{r}

tx <-taxData[rownames(dds),]
nc <- counts(dds, normalize = DNORM)
ac <- sum(nc)

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.8),]) / ac * 100))), 2),
  "0.65" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.65),]) / ac * 100))), 2),
  "0.5" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.5),]) / ac * 100))), 2)
)

```

## Abundance

```{r}
abundance_plot <- ggplot(
  data = as.data.frame(colData(dds)), 
  aes(x = trial, y = copy_number, colour = cultivar, shape = planting_season)
) + geom_jitter() + 
  scale_colour_manual(values = cbPalette)

ggsave(
  filename = "bac_abundance.png", plot = abundance_plot, path = "figures/", 
  height = 20, width = 20, units = "cm"
)

abundance_plot

# Formula for ANOVA
formula <- update(DESIGN, copy_number ~ .)

abundance_anova <- aovp(formula, data = as.data.frame(colData(dds)))
summary(abundance_anova)
```

# Alpha diversity analysis

## Alpha diversity plot

```{r}

# plot alpha diversity - plot_alpha will convert normalised abundances to integer values

bac_alpha_plot <- plot_alpha(
  counts(dds,normalize = F), colData(dds),
  design = "cultivar", colour = "trial",
  measures = c("Shannon", "Simpson"),
  type="box"
) + 
  scale_colour_manual(values = cbPalette) + 
  theme(axis.title.x =  element_blank()) + 
  ggtitle("Bacterial α-diversity") + 
  labs(colour = "Site")
  # facet_wrap(~planting_season)

ggsave(
  filename = "bac_alpha.png", plot = bac_alpha_plot, path = "figures/", 
  height = 20, width = 40, units = "cm"
)

bac_alpha_plot
```

## Permutation based anova on diversity index ranks

```{r}
# get the diversity index data
all_alpha_ord <- plot_alpha(
  counts(dds, normalize = F), colData(dds), design = "trial", returnData = T
)

# join diversity indices and metadata
all_alpha_ord <- all_alpha_ord[
  as.data.table(colData(dds), keep.rownames = "Samples"), on = "Samples"
]

formula <- DESIGN
```

### Chao1

```{r}
setkey(all_alpha_ord, S.chao1)
all_alpha_ord[, measure := as.numeric(as.factor(S.chao1))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

### Shannon

```{r}
setkey(all_alpha_ord, shannon)
all_alpha_ord[, measure := as.numeric(as.factor(shannon))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

### Simpson

```{r}
setkey(all_alpha_ord, simpson)
all_alpha_ord[, measure := as.numeric(as.factor(simpson))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

# Beta diversity PCA/NMDS

## PCA 
```{r}

# perform PC decomposition of DES object
mypca <- des_to_pca(dds)

# to get pca plot axis into the same scale create a dataframe of PC scores multiplied by their variance
d <- t(data.frame(t(mypca$x) * mypca$percentVar))

formula = DESIGN
```

### Percent variation in first 4 PCs 
```{r}
round(mypca$percentVar[1:4], 3)
```

### ANOVA of first 4 PCs
```{r} 
apply(
  mypca$x[, 1:4], 2, 
  function(x){
    summary(aov(update(formula, x ~ .), data = as.data.frame(cbind(x, colData(dds)))))
  }
)
```

### PCA plot
```{r, fig.width=8,fig.height=5}

bac_pca_plot <- plotOrd(
  d,
  colData(dds),
  design = "cultivar",
  shape = "trial",
  axes = c(1, 2),
  facet = "planting_season", 
  cbPalette = T,
  alpha = 0.75,
) #+ facet_wrap(~facet) 

ggsave(filename = "bac_pca_plot.png", plot = bac_pca_plot, path = "figures/")

bac_pca_plot
```

### PCA sum of squares (% var)

```{r}
sum_squares <- apply(mypca$x, 2 ,function(x) 
  summary(aov(update(formula, x ~ .), data = cbind(x, colData(dds))))[[1]][2]
)
sum_squares <- do.call(cbind, sum_squares)
x <- t(apply(sum_squares, 2, prop.table))
perVar <- x * mypca$percentVar
#colSums(perVar)
round(colSums(perVar) / sum(colSums(perVar)) * 100, 3)
```

## ADONIS

```{r}
vg <- vegdist(t(counts(dds, normalize = DNORM)), method = "bray")
set.seed(sum(utf8ToInt("Hamish McLean")))
adonis2(update(formula, vg ~ .), colData(dds), permutations = 1000)
```

## NMDS ordination

```{r}
set.seed(sum(utf8ToInt("Hamish McLean")))
ord <- metaMDS(vg,trace=0) 
#sratmax=20000,maxit=20000,try = 177, trymax = 177

nmds <- scores(ord)

bac_nmds_plot <- plotOrd(
  nmds, colData(dds), design = Factor2, 
  shape = Factor1, alpha = 0.75, cbPalette = T
) + theme(text = element_text(size = 14))

ggsave(filename = "fun_nmds_plot.png", plot = bac_nmds_plot, path = "figures/")

bac_nmds_plot
```

### NMDS with phylum or class arrows

```{r} 
otus <- scores(ord,"species") 

taxmerge <-data.table(inner_join(data.table(OTU=rownames(otus),as.data.frame(otus)),data.table(OTU=rownames(taxData),taxData))) 
taxmerge$phy <- taxaConfVec(taxmerge[,c(-1:-3,-8)],conf=0.9,level=which(colnames(taxmerge[,c(-1:-3,-8)])=="phylum"))
taxmerge$cls <- taxaConfVec(taxmerge[,c(-1:-3,-8)],conf=0.9,level=which(colnames(taxmerge[,c(-1:-3,-8)])=="class")) 

phy <- taxmerge[,lapply(.SD,mean),by=phy,.SDcols=c("NMDS1","NMDS2")]
cls <- taxmerge[,lapply(.SD,mean),by=cls,.SDcols=c("NMDS1","NMDS2")]

bac_nmds_plot + geom_segment(inherit.aes = F,data=phy,aes(xend=NMDS1,yend=NMDS2,x=0,y=0),size=1.5,arrow=arrow()) + 
  geom_text(inherit.aes = F,data=phy,aes(x=NMDS1,y=(NMDS2+sign(NMDS2)*0.05),label=phy))

ggsave(filename = "fun_nmds_phy.png", plot = bac_nmds_plot, path = "figures/")
``` 


<!-- #=============================================================================== -->
#       differential analysis
<!-- #=============================================================================== -->

## DESeq design 
```{r}

# p value for FDR cutoff
alpha <- 0.1

# add design to dds object
design(dds) <- formula

# run model
dds <- DESeq(dds,parallel=F)

# build results table
res <- results(dds,alpha=alpha,contrast=c("Status","Diseased","Healthy"))

```

## Result summary

Rank is lowest taxonomic rank with >=0.65 confidence

### All samples
```{r}
summary(res)

# merge DESeq results with taxonomy
res.merge <- as.data.table(res,keep.rownames="OTU")[
  as.data.table(taxData,keep.rownames="OTU"),on="OTU"]

# print sig. results
res.merge[padj<=alpha,.(OTU,rank,
                        baseMean=round(baseMean,2),
                        FC=round(log2FoldChange,2),
                        padj=round(padj,4))][order(FC,decreasing = T),]

```

<!-- ### Write results -->
<!-- ```{r} -->

<!-- fwrite(res.merge,paste(RHB,"_DES.txt"),quote=F,na="",sep="\t") -->
<!-- fwrite(res2.merge,paste(RHB,"_DES_Paired.txt"),quote=F,na="",sep="\t") -->

<!-- ``` -->

# Differential analysis

## DESeq design

```{r}

# P value for FDR cutoff
alpha <- ALPHA

# Model design
formula <- ~ mainstem

# Add design to dds object
design(dds) <- formula

# Run model
dds <- DESeq(dds, parallel=F)

# Build results table
res <- results(dds, alpha = alpha)


```

### Result summary

Rank is lowest taxonomic rank with >=0.65 confidence

### All samples

```{r}
summary(res)

# merge DESeq results with taxonomy
res.merge <- as.data.table(res,keep.rownames="OTU")[
  as.data.table(taxData,keep.rownames="OTU"),on="OTU"]

# print sig. results
res.merge[padj<=alpha,.(OTU,rank,
                        baseMean=round(baseMean,2),
                        FC=round(log2FoldChange,2),
                        padj=round(padj,4))][order(FC,decreasing = T),]

```