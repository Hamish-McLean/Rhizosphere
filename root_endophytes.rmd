---
title: "Root endophyte analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(comment = "#")
knitr::opts_chunk$set(fig.width = 9, fig.height = 9)
knitr::opts_chunk$set(error = TRUE)
```

# Setup

## Libraries

```{r libraries}
library(DESeq2)
library(tidyverse)
library(data.table)
library(vegan)
library(lmPerm)
library(viridis)
library(grid)
library(gridExtra)
library(cowplot)
library(iNEXT)

# library(devtools)
# install_github("eastmallingresearch/Metabarcoding_pipeline/scripts")
library(metafuncs)
```

## Functions and constants

```{r constants}
ALPHA =      0.1   # DESeq2 alpha value
OTUFILTER =  0.01  # Remove OTUs with proportion of total reads below value
READFILTER = 0.05  # Will remove samples with read sum below sample_median_reads*READFILTER 
PAIREDONLY = F     # Will remove the pair of samples which fail the readfilter - probably only useful for DESeq separated by type NOTE removes pairs before DESeq object is created   
TAXCONF =    0.80  # Sets the taxonomy confidence level to get "rank" in taxonomy files
TOPOTU =     10    # Number of Top OTUs for summary information
DIFFOTU =    200    # Number of Top OTUs for correlation analysis

DNORM =      T     # Boolean for DeSeq2 normalisation

# graphics
DEVICE =     "png"
DPI =        1200
WIDTH =      9
HEIGHT =     9

# Model design
Factor1 = "site"
Factor2 = "cultivar"
DESIGN = y ~ site + planting_season + cultivar
```

```{r functions}
# colour blind palette
cbPalette <- c(
  "#000000", "#E69F00", "#56B4E9", "#009E73", 
  "#F0E442", "#0072B2", "#D55E00", "#CC79A7"
)

# source("functions/rarefaction.R")
source("functions/metabarcoding.R")
source("functions/loadme.R")
```

# Load data

Bacterial and fungal ASV (ZOTU) tables, sample metadata, and taxonomy files are
loaded into named lists using the `loadData` function from Greg's `metafuncs` 
package.

```{r data}
metadata <- "sample_metadata.txt"

# Load data
ubiome_BAC <- loadData("data/BAC.zotu_table.txt",metadata,"data/zBAC.sintax.taxa",RHB="BAC")
ubiome_FUN <- loadData("data/FUN.zotu_table.txt",metadata,"data/zFUN.sintax.taxa",RHB="FUN")

# Correct for planting date month variability.
# March and April are replaced by spring, December by winter.
ubiome_BAC$colData <- ubiome_BAC$colData %>%
  mutate(
    planting_season = case_when(
      planting_date %in% c("march", "april") ~ "spring",
      planting_date %in% c("dec") ~ "winter"
    )
  )

ubiome_FUN$colData <- ubiome_FUN$colData %>%
  mutate(
    planting_season = case_when(
      planting_date %in% c("march", "april") ~ "spring",
      planting_date %in% c("dec") ~ "winter"
    )
  )
```

## Global removals

```{r}
# Sample "A2-7" removed due to missampling.
ubiome_BAC$colData <- ubiome_BAC$colData[!rownames(ubiome_BAC$colData) %in% "HMA27", ]
ubiome_BAC$countData <- ubiome_BAC$countData[, !colnames(ubiome_BAC$countData) %in% "HMA27"]
ubiome_FUN$colData <- ubiome_FUN$colData[!rownames(ubiome_FUN$colData) %in% "HMA27", ]
ubiome_FUN$countData <- ubiome_FUN$countData[, !colnames(ubiome_FUN$countData) %in% "HMA27"]
```

# Filter samples and OTUs

## Filtering taxa

Plantae taxa are filtered from fungal `taxData`.
Chloroplast and Eukaryote  taxa are filtered from bacterial `taxData`.
Corresponding OTUs are removed from `countData`.

```{r filter_taxa}
# Filter Plant, Chloroplast, and Eukaryote OTUs

# Fungi: Plantae OTUs
cat("Fungi:", length(grep("Plantae", ubiome_FUN$taxData$kingdom)), "Plantae OTUs\n")

# Bacteria: Chloroplast (Streptophyta) and Eukaryote OTUs
cat(
  "Bacteria:", length(grep("Streptophyta", ubiome_BAC$taxData$genus)), "Chloroplast OTUs;", 
  length(grep("Eukaryota", ubiome_BAC$taxData$kingdom)), "Eukaryote OTUs\n"
)

# Filter Chloroplast and Eukaryote
filt <- rownames(
  ubiome_BAC$taxData[
    grepl("Streptophyta", ubiome_BAC$taxData$genus) & 
    as.numeric(ubiome_BAC$taxData$g_conf) >= TAXCONF,
  ]
)

filt <- c(filt, rownames(ubiome_BAC$taxData[grep("Eukaryota", ubiome_BAC$taxData$kingdom), ]))

cat("Bacteria: removing", length(filt), "OTUs")

ubiome_BAC$taxData <- ubiome_BAC$taxData[!rownames(ubiome_BAC$taxData) %in% filt, ]
ubiome_BAC$countData <- ubiome_BAC$countData[!rownames(ubiome_BAC$countData) %in% filt, ]
```

## Filtering samples

Plot rarefaction curves.

Remove samples with read count below `r READFILTER * 100` % of median.

```{r filter_samples}
invisible(mapply(assign, names(ubiome_BAC), ubiome_BAC, MoreArgs = list(envir = globalenv())))
rare_bac <- gfunc(countData, colData, "Bacteria")
# rare_bac <- gfunc(as.data.frame(counts(dds)), as.data.frame(colData(dds)), "Bacteria ZOTU")
invisible(mapply(assign, names(ubiome_FUN), ubiome_FUN, MoreArgs = list(envir = globalenv())))
rare_fun <- gfunc(countData, colData, "Fungi")
# rare_fun <- gfunc(as.data.frame(counts(dds)), as.data.frame(colData(dds)), "Fungi ZOTU")

rarefaction_plots <- grid.arrange(
  rare_bac, rare_fun,
  left = textGrob(label = expression("log"[10] * " aligned sequenecs"), rot = 90),
  bottom = "ASV count", nrow = 2
)

ggsave(filename = "rarefaction_plots.png", plot = rarefaction_plots, path = "figures/")

rarefaction_plots

# Fungi
med <- median(colSums(ubiome_FUN$countData))
filt <- !colSums(ubiome_FUN$countData) > med * READFILTER
cat("Fungi: ",sum(filt),"sample(s) removed\n")

# Bacteria
med <- median(colSums(ubiome_BAC$countData))
filt <- !colSums(ubiome_BAC$countData) > med * READFILTER
cat("Bacteria: ",sum(filt),"sample(s) removed\n")
```

## Filter ASVs

### ASV read count

Number of ASVs which account for 50 %, 80 %, and 99 % of total reads.

```{r}
asv_propotions <- function(countData, proportion){
  i <- sum(countData)
  y <- rowSums(countData)
  y <- y[order(y, decreasing = T)]
  asvs <- length(y[(cumsum(y) / i <= proportion)])
  return(asvs)
}

proportions <- c(0.5, 0.9, 0.99, 1)

top_asvs <- data.table(
  "proportion" = proportions,
  "Fungi" = lapply(proportions, function(x) asv_propotions(ubiome_FUN$countData, x)),
  "Bacteria" = lapply(proportions, function(x) asv_propotions(ubiome_BAC$countData, x))
)

top_asvs
```

### Filter ASVs

Remove ASVs with read count below `r OTUFILTER * 100` % of total reads.

```{r filter_reads}
# Fungi
keep <- filter_otus(ubiome_FUN$countData, OTUFILTER)
cat("Fungi: removing", nrow(ubiome_FUN$countData) - length(keep), "OTUs\n")

ubiome_FUN$taxData <- ubiome_FUN$taxData[rownames(ubiome_FUN$taxData) %in% keep,]
ubiome_FUN$countData <- ubiome_FUN$countData[rownames(ubiome_FUN$countData) %in% keep,]

# Bacteria
keep <-  filter_otus(ubiome_BAC$countData, OTUFILTER)
cat("Bacteria: removing", nrow(ubiome_BAC$countData) - length(keep), "OTUs")

ubiome_BAC$taxData <- ubiome_BAC$taxData[rownames(ubiome_BAC$taxData) %in% keep,]
ubiome_BAC$countData <- ubiome_BAC$countData[rownames(ubiome_BAC$countData) %in% keep,]
```

# Absolute abundance normalisation

OTU normalisation is performed using qPCR theoretical copy number data.
Copy number is calculated per mg of root sample from the qPCR data.

## Prepare qPCR abundance data

```{r abundance}
abundance <- fread("mean_abundance.csv")

# Add sample ID to abundance data
abundance$id <- paste0("HM", gsub("-", "", abundance$Sample))
# abundance$id <- abundance$Sample
abundance$copy_number <- abundance$MeanAdjustedTCN_mg

# Add bacterial (16S) and fungal (ITS) abundance to ubiome BAC and FUN named lists
ubiome_FUN$abundance <- abundance[abundance$Target == "ITS"] %>%
  column_to_rownames(var = "id")
ubiome_BAC$abundance <- abundance[abundance$Target == "16S"] %>%
  column_to_rownames(var = "id")

# Merge copy number from abundance with colData
ubiome_FUN$colData <- merge(
  ubiome_FUN$colData, 
  ubiome_FUN$abundance[, c("Target", "copy_number")], 
  by = 0
) %>% column_to_rownames(var = "Row.names")
ubiome_BAC$colData <- merge(
  ubiome_BAC$colData, 
  ubiome_BAC$abundance[, c("Target", "copy_number")], 
  by = 0
) %>% column_to_rownames(var = "Row.names")
```

### Remove outliers

```{r}
# Detect outliers with std > threshold from the median
detect_outliers <- function(x, val, threshold, na.rm = TRUE) {
  med_x <- median(x[[val]], na.rm = na.rm)
  sd_x <- sd(x[[val]], na.rm = na.rm)
  outliers <- x[x[[val]] > (med_x + threshold * sd_x) | x[[val]] < (med_x - threshold * sd_x), ]
  return(outliers)
}

outliers_FUN <- detect_outliers(ubiome_FUN$abundance, "MeanAdjustedTCN_mg", 3)
outliers_BAC <- detect_outliers(ubiome_BAC$abundance, "MeanAdjustedTCN_mg", 3)

# Remove samples with copy number > 3 std from the median
outliers <- rownames(outliers_FUN)
ubiome_FUN$abundance <- ubiome_FUN$abundance[!rownames(ubiome_FUN$abundance) %in% outliers, ]
ubiome_FUN$countData <- ubiome_FUN$countData[, !colnames(ubiome_FUN$countData) %in% outliers]
ubiome_FUN$colData <- ubiome_FUN$colData[!rownames(ubiome_FUN$colData) %in% outliers, ]

cat("Fungi: removing", length(outliers), "outlier(s)\n")
```

Sample A1-3 is removed from the fungal data due to abnormally high copy number.

# Canker count data

Canker count data for differential expression analysis.

Area under the disease progression curve (AUDPC) is calculated for each tree
using the formula $$\sum_{i=1}^{n-1} \frac{(y_i + y_{i+1})}{2} (x_{i+1} - x_i)$$
where $y_i$ is the canker count at time $x_i$.

```{r canker_data}
# Canker count data for sampled trees only

all_canker_data <- fread("all_canker_data.csv")

# Remove spaces from column names and convert to lowercase
colnames(all_canker_data) <- tolower(gsub(" ", "_", colnames(all_canker_data)))

# Add planting season to canker data and set tree_id and id columns
all_canker_data <- mutate(
  all_canker_data,
  planting_season = case_when(
    planting_date %in% c("March", "April") ~ "spring",
    planting_date %in% c("Dec") ~ "winter"
  ),
  tree_id = id,
  id = substr(tree_id, 1, 4)
)

# Filter canker data to match tree id

```

```{r}
all_canker_data <- fread("all_canker_data.csv")

# Remove spaces from column names and convert to lowercase
colnames(all_canker_data) <- tolower(gsub(" ", "_", colnames(all_canker_data)))

# Add planting season to canker data and set tree_id and id columns
all_canker_data <- mutate(
  all_canker_data,
  planting_season = case_when(
    planting_date %in% c("March", "April") ~ "spring",
    planting_date %in% c("Dec") ~ "winter"
  ),
  tree_id = id,
  id = substr(tree_id, 1, 4)
)

# Filter canker data to match both id and planting season from colData
all_canker_data <- all_canker_data %>% 
  semi_join(ubiome_BAC$colData, by = c("id", "planting_season"))

# Filter out replacement "7 (GD)" trees
all_canker_data <- all_canker_data[all_canker_data$cultivar_number != "7 (GD)", ]

# Sum mainstem and peripheral canker counts
all_canker_data$mainstem_cankers <- all_canker_data$a4 + all_canker_data$b4
all_canker_data$peripheral_cankers <- all_canker_data$c4 + all_canker_data$d4 + all_canker_data$e4
all_canker_data$total_cankers <- all_canker_data$mainstem_cankers + all_canker_data$peripheral_cankers

# Average mainstem and peripheral canker counts per subplot
canker_data <- all_canker_data %>%
  group_by(id, planting_season, cultivar_number, cultivar) %>%
  summarise(
    mainstem_cankers = mean(mainstem_cankers, na.rm = T),
    peripheral_cankers = mean(peripheral_cankers, na.rm = T),
    total_cankers = mean(total_cankers, na.rm = T)
  )

# Add canker data to colData for both FUN and BAC
ubiome_FUN$colData <- merge(
  rownames_to_column(ubiome_FUN$colData, var = "Row.names"), 
  canker_data[, c("id", "mainstem_cankers", "peripheral_cankers", "total_cankers")], 
  by = "id"
) %>% column_to_rownames("Row.names")

ubiome_BAC$colData <- merge(
  rownames_to_column(ubiome_BAC$colData, var = "Row.names"), 
  canker_data[, c("id", "mainstem_cankers", "peripheral_cankers", "total_cankers")], 
  by = "id"
) %>% column_to_rownames("Row.names")
```

# Create DESeq objects

```{r DESeq}
# Make sure countData and colData still match, if they do, create DESeq objects, if not throw error
if(identical(colnames(ubiome_FUN$countData), rownames(ubiome_FUN$colData))) {
  # Create DESeq object
  ubiome_FUN$dds <- ubiom_to_des(ubiome_FUN)
  print("FUN DESeq object created")
} else {
  stop("FUN countData and colData do not match")
}

if(identical(colnames(ubiome_BAC$countData), rownames(ubiome_BAC$colData))) {
  # Create DESeq object
  ubiome_BAC$dds <- ubiom_to_des(ubiome_BAC)
  print("BAC DESeq object created")
} else {
  stop("BAC countData and colData do not match")
}
```


# Create DESeq objects
ubiome_FUN$dds <- ubiom_to_des(ubiome_FUN)
ubiome_BAC$dds <- ubiom_to_des(ubiome_BAC)
```

# Abundance normalisation

Absolute abundance normalisation using DESeq2 size factors.

Values are centred around the mean of the copy number.

```{r}
# Normalise count data using DESeq2 size factors

ubiome_FUN$dds$sizeFactor <- ubiome_FUN$dds$copy_number / mean(ubiome_FUN$dds$copy_number)
ubiome_BAC$dds$sizeFactor <- ubiome_BAC$dds$copy_number / mean(ubiome_BAC$dds$copy_number)

```

<!-- #=============================================================================== -->
# **Fungi**
<!-- #=============================================================================== -->

```{r}
# Unpack fungi data
invisible(mapply(assign, names(ubiome_FUN), ubiome_FUN, MoreArgs = list(envir = globalenv())))
```

## OTU and sample summary

### Read and sample summary

```{r read_summary}
cat(
  "Raw reads", "\n\n",
  "Total raw reads:\t\t", sum(countData), "\n",
  "Mean raw reads per sample:\t", mean(colSums(countData)), "\n",
  "Median raw reads per sample:\t", median(colSums(countData)), "\n",
  "Max raw reads per sample:\t", max(colSums(countData)), "\n",
  "Min raw reads per sample:\t", min(colSums(countData)), "\n\n"
)
#colSums(countData)

nct <- counts(dds, normalize = T)
cat("Normalised reads", "\n\n",
  "Total normalised reads:\t\t", sum(nct), "\n",
  "Mean normalised reads per sample:\t", mean(colSums(nct)), "\n",
  "Median normalised reads per sample:\t", median(colSums(nct)), "\n",
  "Min normalised reads per sample:\t", min(colSums(nct)), "\n",
  "Max normalised reads per sample:\t", max(colSums(nct)), "\n\n"
)
#round(colSums(counts(dds,normalize = DNORM)),0)
```

### OTU summary 

```{r otu_summary}
cat(
  "Total OTUs:\t\t", nrow(taxData),"\n\n",
  "Raw reads per OTU summary", "\n\n",
  "Mean raw reads per OTU:\t", mean(rowSums(countData)),"\n",
  "Median raw per OTU:\t\t", median(rowSums(countData)),"\n",
  "OTU raw Min reads:\t\t", min(rowSums(countData)),"\n",
  "OTU raw Max reads:\t\t", max(rowSums(countData)),"\n\n"
)

cat(
  "Normalised reads per OTU summary","\n\n",
  "Mean normalised reads per OTU:\t\t", mean(rowSums(nct)),"\n",
  "Median normalised reads per OTU:\t", median(rowSums(nct)),"\n",
  "OTU normalised Min reads:\t\t", min(rowSums(nct)),"\n",
  "OTU normalised Max reads:\t\t", max(rowSums(nct)),"\n\n"
)

y <- rowSums(nct)
y <- y[order(y, decreasing = T)]
# proportion
xy <- y / sum(y)

cat("Top " ,TOPOTU, "OTUs:\n")
data.frame(counts = y[1:TOPOTU], proportion = xy[1:TOPOTU], rank = taxData[names(y)[1:TOPOTU],]$rank)
```

## Taxonomy Summary

### Taxonomy identifiable

Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank.

```{r}

# Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank

tx <- copy(taxData)
setDT(tx)
cols <- names(tx)[9:15]

tx[, (cols) := lapply(.SD, as.factor), .SDcols = cols]

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.8) / nrow(tx))), 2),
  "0.65" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.65) / nrow(tx))), 2),
  "0.5" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.5) / nrow(tx))), 2)
)
```

% of reads which can be assigned to each taxonomic ranks

```{r}

tx <-taxData[rownames(dds),]
nc <- counts(dds, normalize = DNORM)
ac <- sum(nc)

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.8),]) / ac * 100))), 2),
  "0.65" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.65),]) / ac * 100))), 2),
  "0.5" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.5),]) / ac * 100))), 2)
)

```

## Abundance

Plot copy number for each sample grouped by site, cultivar, and planting season.
Test the effect of site, cultivar, and planting season on copy number using ANOVA.

```{r}
abundance_plot <- ggplot(
  data = as.data.frame(colData(dds)), 
  aes(x = site, y = copy_number, colour = cultivar, shape = planting_season)
) + geom_jitter() + 
  scale_colour_manual(values = cbPalette)

ggsave(
  filename = "fun_abundance.png", plot = abundance_plot, path = "figures/", 
  height = 20, width = 20, units = "cm"
)

abundance_plot

# Formula for ANOVA
formula <- update(DESIGN, copy_number ~ .)

abundance_anova <- aovp(formula, data = as.data.frame(colData(dds)))
summary(abundance_anova)

abundance_resid <- data.frame(residuals = residuals(abundance_anova))

norm <- ggplot(abundance_resid, aes(sample = residuals)) + stat_qq() + stat_qq_line()
ggsave(
  filename = "fun_abundance_norm.png", plot = norm, path = "figures/", 
  height = 20, width = 20, units = "cm"
)

norm
```

# Alpha diversity analysis

## Alpha diversity plot

```{r fun_alpha_diversity}

# plot alpha diversity - plot_alpha will convert normalised abundances to integer values

fun_alpha_plot <- plot_alpha(
  counts(dds, normalize = F), colData(dds),
  design = "cultivar", colour = "site",
  measures = c("Shannon", "Simpson"),
  type = "box"
) + scale_colour_manual(values = cbPalette) + 
  theme(axis.title.x = element_blank()) +
  ggtitle("Fungal α-diversity") + 
  labs(colour = "Site")
  # facet_wrap(~planting_season)

ggsave(
  filename = "fun_alpha.png", plot = fun_alpha_plot, path = "figures/", 
  height = 20, width = 40, units = "cm"
)

fun_alpha_plot
```

## Permutation based anova on diversity index ranks

```{r}
# get the diversity index data
all_alpha_ord <- plot_alpha(
  counts(dds, normalize = F),
  colData(dds),
  returnData = T
)

# join diversity indices and metadata
all_alpha_ord <- all_alpha_ord[
  as.data.table(colData(dds), keep.rownames = "Samples"), 
  on = "Samples"
]

formula <- DESIGN # x ~ site * planting_date * cultivar + site / site.block
```

### Chao1

```{r}
setkey(all_alpha_ord, S.chao1)
all_alpha_ord[, measure := as.numeric(as.factor(S.chao1))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

### Shannon

```{r}
setkey(all_alpha_ord, shannon)
all_alpha_ord[, measure := as.numeric(as.factor(shannon))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

### Simpson

```{r}
setkey(all_alpha_ord, simpson)
all_alpha_ord[, measure := as.numeric(as.factor(simpson))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

# Beta diversity PCA/NMDS

## PCA

```{r}

# Perform PC decomposition of DES object
mypca <- des_to_pca(dds)

# To get pca plot axis into the same scale create a dataframe of PC scores multiplied by their variance
d <- t(data.frame(t(mypca$x) * mypca$percentVar))

formula = DESIGN
```

### Percent variation in first 4 PCs 

```{r}
pca_var <- data.frame(
  row.names = c("PC1", "PC2", "PC3", "PC4"),
  perc_var = round(mypca$percentVar[1:4] * 100, 3)
)

pca_var
```

### ANOVA of first 4 PCs

```{r} 
pca_summary <- apply(
  mypca$x[, 1:4], 2, 
  function(x){
    summary(aov(update(formula, x ~ .), data = as.data.frame(cbind(x, colData(dds)))))
  }
)

pca_summary
```

### Percent variation in first 4 PCs for each factor

```{r}
pcas <- list(
  PC1 = data.frame(unclass(pca_summary$PC1)),
  PC2 = data.frame(unclass(pca_summary$PC2)),
  PC3 = data.frame(unclass(pca_summary$PC3)),
  PC4 = data.frame(unclass(pca_summary$PC4))
)

pca_factors <- data.table(
  PCs = names(pcas),
  total_var = pca_var$perc_var,
  site_var = sapply(pcas, function(x) (x['site', 'Sum.Sq'] / sum(x['Sum.Sq'])) * 100),
  site_p = sapply(pcas, function(x) x['site', 'Pr..F.']),
  cultivar_var = sapply(pcas, function(x) (x['cultivar', 'Sum.Sq'] / sum(x['Sum.Sq'])) * 100),
  cultivar_p = sapply(pcas, function(x) x['cultivar', 'Pr..F.']),
  season_var = sapply(pcas, function(x) (x['planting_season', 'Sum.Sq'] / sum(x['Sum.Sq'])) * 100),
  season_p = sapply(pcas, function(x) x['planting_season', 'Pr..F.']),
  residuals_var = sapply(pcas, function(x) (x['Residuals', 'Sum.Sq'] / sum(x['Sum.Sq'])) * 100)
)

pca_factors
```

### PCA plot

```{r, fig.width = 8, fig.height = 5}

pca_plot <- plotOrd(
  d,
  colData(dds),
  design = "cultivar",
  shape = "site",
  axes = c(1, 2),
  facet = "planting_season", 
  cbPalette = T,
  alpha = 0.75,
) # + facet_wrap(~facet) 
#   geom_line(aes(group=facet),alpha=0.25,linetype=3,colour="#000000") + 
#   theme(text = element_text(size=14))

ggsave(filename = "fun_pca_plot.png", plot = pca_plot, path = "figures/")

pca_plot
```

### PCA sum of squares (% var)

```{r}
sum_squares <- apply(mypca$x, 2 ,function(x) 
  summary(aov(update(formula, x ~ .), data = cbind(x, colData(dds))))[[1]][2]
)
sum_squares <- do.call(cbind, sum_squares)
x <- t(apply(sum_squares, 2, prop.table))
perVar <- x * mypca$percentVar
#colSums(perVar)
round(colSums(perVar) / sum(colSums(perVar)) * 100, 3)
```

## ADONIS

```{r}
vg <- vegdist(t(counts(dds, normalize = T)), method = "bray")
set.seed(sum(utf8ToInt("Hamish McLean")))
adonis2(update(formula, vg ~ .), colData(dds), permutations = 1000)
```

## NMDS ordination

```{r}
set.seed(sum(utf8ToInt("Hamish McLean")))
ord <- metaMDS(vg,trace=0) 
#sratmax=20000,maxit=20000,try = 177, trymax = 177

nmds <- scores(ord)

nmds_plot <- plotOrd(
  nmds, colData(dds), design = Factor2, 
  shape = Factor1, alpha = 0.75, cbPalette = T
) + theme(text = element_text(size = 14))

ggsave(filename = "fun_nmds_plot.png", plot = nmds_plot, path = "figures/")

nmds_plot
```

### NMDS with phylum or class arrows 

```{r} 
otus <- scores(ord, "species") 

taxmerge <- data.table(
  inner_join(
    data.table(OTU = rownames(otus), as.data.frame(otus)),
    data.table(OTU = rownames(taxData), taxData))
) 
taxmerge$phy <- taxaConfVec(
  taxmerge[, c(-1:-3, -8)], conf = 0.9,
  level = which(colnames(taxmerge[, c(-1:-3, -8)]) == "phylum")
)
taxmerge$cls <- taxaConfVec(
  taxmerge[, c(-1:-3, -8)], conf = 0.9,
  level = which(colnames(taxmerge[, c(-1:-3, -8)]) == "class")
) 

phy <- taxmerge[,lapply(.SD,mean),by=phy,.SDcols=c("NMDS1","NMDS2")]
cls <- taxmerge[,lapply(.SD,mean),by=cls,.SDcols=c("NMDS1","NMDS2")]

nmds_plot + geom_segment(
  inherit.aes = F, data = phy, 
  aes(xend = NMDS1, yend = NMDS2, x = 0, y = 0), 
  size = 1.5, arrow = arrow()
) + 
  geom_text(
    inherit.aes = F, data = phy, 
    aes(x = NMDS1, y = (NMDS2 + sign(NMDS2) * 0.05), label = phy)
  )

ggsave(filename = "fun_nmds_phy.png", plot = nmds_plot, path = "figures/")

fun_nmds_plot
```

# ASV abundance

## Filter top ASVs

```{r top ASVs}
# Extract normalised counts from DESeq object
nc <- counts(dds, normalize = T) %>% as.data.frame()

# Filter the top x abundant OTUs by the sum of their normalised counts
top_otus <- nc[order(rowSums(nc), decreasing = T)[1:DIFFOTU], ]

# Check that sample names match
identical(names(top_otus), rownames(colData))

# Extract taxonomic data for top OTUs
top_taxa <- taxData[rownames(top_otus), ]

# Log transform normalised counts
top_otus <- log10(top_otus + 1)
```

## Effect of design factors on abundance of top ASVs

Effect of site, cultivar, and planting season on abundance of top `r DIFFOTU` ASVs

```{r ASV anova}
top_otu_data <- data.frame(t(top_otus))
top_otu_ids <- rownames(top_otus)
identical(rownames(top_otu_data), rownames(colData))

top_otu_data <- merge(top_otu_data, colData, by = 0) %>% column_to_rownames("Row.names")

otu_anova <- function(otu, formula, data) {
  a = data.frame(unclass(summary(aov(update(formula, paste(otu, "~ .")), data = data))))
  d = data.frame(
    OTU = otu,
    Taxonomy = taxData[otu, "rank"],
    site_var = a['site', 'Sum.Sq'] / sum(a$Sum.Sq) * 100,
    site_p = a['site', 'Pr..F.'],
    cultivar_var = a['cultivar', 'Sum.Sq'] / sum(a$Sum.Sq) * 100,
    cultivar_p = a['cultivar', 'Pr..F.'],
    season_var = a['planting_season', 'Sum.Sq'] / sum(a$Sum.Sq) * 100,
    season_p = a['planting_season', 'Pr..F.'],
    residuals_var = a['Residuals', 'Sum.Sq'] / sum(a$Sum.Sq) * 100
  )
  return(d)
}

formula <- DESIGN

otu_anova_results <- data.table(t(sapply(top_otu_ids, function(x) otu_anova(x, formula, top_otu_data))))

otu_anova_results_adjusted <- otu_anova_results %>% 
  mutate(
    site_p = p.adjust(site_p, method = "BH"),
    cultivar_p = p.adjust(cultivar_p, method = "BH"),
    season_p = p.adjust(season_p, method = "BH")
  )

otu_anova_results_adjusted

nrow(otu_anova_results_adjusted[otu_anova_results_adjusted$site_p < 0.05, ])
nrow(otu_anova_results_adjusted[otu_anova_results_adjusted$cultivar_p < 0.05, ])
```

# Correlations

## Correlation of abundance of top `r DIFFOTU` ASVs with canker count

```{r ASV correlations}
# Calculate Pearson correlation for each OTU with mainstem canker count for each sample from colData
correlations <- data.table(
  OTU = rownames(top_otus),
  Taxonomy = top_taxa$rank,
  pearson = apply(top_otus, 1, function(x) cor.test(x, colData$total_cankers, method = "pearson")$estimate),
  spearman = apply(top_otus, 1, function(x) cor.test(x, colData$total_cankers, method = "spearman", exact = F)$estimate),
  p_pearson = apply(top_otus, 1, function(x) cor.test(x, colData$total_cankers, method = "pearson")$p.value),
  p_spearman = apply(top_otus, 1, function(x) cor.test(x, colData$total_cankers, method = "spearman", exact = F)$p.value)
)

# Adjust p-values for multiple testing
correlations$p_pearson_adjusted <- p.adjust(correlations$p_pearson, method = "BH")
correlations$p_spearman_adjusted <- p.adjust(correlations$p_spearman, method = "BH")

correlations
```

## Correlation of abundance of top `r DIFFOTU` ASVs with canker count for each site

```{r ASV site correlations}
samples <- list(
  Avalon = rownames(colData[colData$site == "Avalon", ]), 
  Scripps = rownames(colData[colData$site == "Scripps", ]), 
  WWF = rownames(colData[colData$site == "WWF", ])
)

# Calculate correlations for OTU abundance for each site with canker count
correlate_site <- function(site, method, result){
  otus = top_otus[ , samples[[site]]]
  cankers = colData[colData$site == site, ]$total_cankers
  apply(
    otus, 1, function(x) cor.test(
      as.numeric(x), as.numeric(cankers), 
      method = method, exact = F
    )[[result]]
  )
}

a_correlations <- data.table(
  OTU = rownames(top_otus),
  Taxonomy = top_taxa$rank,
  a_pearson = correlate_site("Avalon", "pearson", "estimate"),
  a_spearman = correlate_site("Avalon", "spearman", "estimate"),
  a_p_pearson = correlate_site("Avalon", "pearson", "p.value"),
  a_p_spearman = correlate_site("Avalon", "spearman", "p.value")
)
a_correlations$a_p_pearson_adjusted <- p.adjust(a_correlations$a_p_pearson, method = "BH")
a_correlations$a_p_spearman_adjusted <- p.adjust(a_correlations$a_p_spearman, method = "BH")

s_correlations <- data.table(
  OTU = rownames(top_otus),
  Taxonomy = top_taxa$rank,
  s_pearson = correlate_site("Scripps", "pearson", "estimate"),
  s_spearman = correlate_site("Scripps", "spearman", "estimate"),
  s_p_pearson = correlate_site("Scripps", "pearson", "p.value"),
  s_p_spearman = correlate_site("Scripps", "spearman", "p.value")
)
s_correlations$s_p_pearson_adjusted <- p.adjust(s_correlations$s_p_pearson, method = "BH")
s_correlations$s_p_spearman_adjusted <- p.adjust(s_correlations$s_p_spearman, method = "BH")

w_correlations <- data.table(
  OTU = rownames(top_otus),
  Taxonomy = top_taxa$rank,
  w_pearson = correlate_site("WWF", "pearson", "estimate"),
  w_spearman = correlate_site("WWF", "spearman", "estimate"),
  w_p_pearson = correlate_site("WWF", "pearson", "p.value"),
  w_p_spearman = correlate_site("WWF", "spearman", "p.value")
)
w_correlations$w_p_pearson_adjusted <- p.adjust(w_correlations$w_p_pearson, method = "BH")
w_correlations$w_p_spearman_adjusted <- p.adjust(w_correlations$w_p_spearman, method = "BH")

site_correlations <- rbind(a_correlations, s_correlations, w_correlations)
```

### ASV correlation summary

Summary of the top `r DIFFOTU` ASVs with statistically significant (*P* < 0.05)
adjusted Pearson or Spearman correlation with canker count.
Taxonomy assigned at > `r TAXCONF * 100` % confidence.

```{r ASV correlation summary}
a <- 0.001

# Correlations where p_pearson < a or p_spearman < a
correlations[correlations$p_pearson_adjusted < a | correlations$p_spearman_adjusted < a, ]
```

## Correlation of α-diversity with canker count

```{r α-diversity correlations}
measures <- c("shannon", "simpson") #, "S.chao1", "S.obs", "S.ACE")
corr_methods <- c("pearson", "spearman")

# Calculate correlations for each α-diversity measure with canker count
correlate_alpha <- function(df, canker_count, measures, corr_methods, return) {
  mat <- sapply(
    corr_methods, 
    function(x) sapply(
      measures, 
      function(y) cor.test(df[[y]], df[[canker_count]], method = x, exact = F)[[return]]
    )
  )
  return(c(mat[,1], mat[,2]))
}

alpha_correlations <- data.table(
  measure = rep(measures, each = length(corr_methods)),
  method = rep(corr_methods, times = length(measures)),
  estimate = correlate(all_alpha_ord, "total_cankers", measures, corr_methods, "estimate"),
  p_value = correlate(all_alpha_ord, "total_cankers", measures, corr_methods, "p.value")
)

# Adjust p-values for multiple testing
alpha_correlations$p_adjusted <- p.adjust(alpha_correlations$p_value, method = "BH")

alpha_correlations
```

## Correlation of β-diversity PCs with canker count

```{r β-diversity correlations}
no_pcs <- 4

# Merge PC scores with canker data
pc_scores <- merge(colData, data.frame(mypca$x[, 1:no_pcs]), by = "row.names") %>% 
  column_to_rownames("Row.names")

pcs <- tail(colnames(pc_scores), no_pcs)

# Calculate correlations for each PC with canker count
beta_correlations <- data.table(
  PC = rep(1:no_pcs, each = length(corr_methods)),
  method = rep(corr_methods, times = no_pcs),
  estimate = correlate(pc_scores, "total_cankers", pcs, corr_methods, "estimate"),
  p_value = correlate(pc_scores, "total_cankers", pcs, corr_methods, "p.value")
)

# Adjust p-values for multiple testing
beta_correlations$p_adjusted <- p.adjust(beta_correlations$p_value, method = "BH")

beta_correlations
```

<!-- #=============================================================================== -->
# **Bacteria**
<!-- #=============================================================================== -->

```{r}
# Unpack bacteria data
invisible(mapply(assign, names(ubiome_BAC), ubiome_BAC, MoreArgs = list(envir = globalenv())))
```

## OTU and sample summary

### Read and sample summary

```{r}
cat(
  "Raw reads", "\n\n",
  "Total raw reads:\t\t", sum(countData), "\n",
  "Mean raw reads per sample:\t", mean(colSums(countData)), "\n",
  "Median raw reads per sample:\t", median(colSums(countData)), "\n",
  "Max raw reads per sample:\t", max(colSums(countData)), "\n",
  "Min raw reads per sample:\t", min(colSums(countData)), "\n\n"
)
#colSums(countData)

nct <- counts(dds, normalize = T)
cat("Normalised reads", "\n\n",
  "Total normalised reads:\t\t", sum(nct), "\n",
  "Mean normalised reads per sample:\t", mean(colSums(nct)), "\n",
  "Median normalised reads per sample:\t", median(colSums(nct)), "\n",
  "Min normalised reads per sample:\t", min(colSums(nct)), "\n",
  "Max normalised reads per sample:\t", max(colSums(nct)), "\n\n"
)
#round(colSums(counts(dds,normalize = DNORM)),0)
```

### OTU summary 

```{r}
cat(
  "Total OTUs:\t\t", nrow(taxData),"\n\n",
  "Raw reads per OTU summary", "\n\n",
  "Mean raw reads per OTU:\t", mean(rowSums(countData)),"\n",
  "Median raw per OTU:\t\t", median(rowSums(countData)),"\n",
  "OTU raw Min reads:\t\t", min(rowSums(countData)),"\n",
  "OTU raw Max reads:\t\t", max(rowSums(countData)),"\n\n"
)

cat(
  "Normalised reads per OTU summary","\n\n",
  "Mean normalised reads per OTU:\t\t", mean(rowSums(nct)),"\n",
  "Median normalised reads per OTU:\t", median(rowSums(nct)),"\n",
  "OTU normalised Min reads:\t\t", min(rowSums(nct)),"\n",
  "OTU normalised Max reads:\t\t", max(rowSums(nct)),"\n\n"
)

y <- rowSums(nct)
y <- y[order(y, decreasing = T)]
# proportion
xy <- y/sum(y)

cat("Top ", TOPOTU, "OTUs:\n")
data.frame(counts = y[1:TOPOTU], proportion = xy[1:TOPOTU], rank = taxData[names(y)[1:TOPOTU],]$rank)
```

## Taxonomy Summary

### Taxonomy identifiable

Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank

```{r}

# Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank

tx <- copy(taxData)
setDT(tx)
cols <- names(tx)[9:15]

tx[, (cols) := lapply(.SD, as.factor), .SDcols = cols]

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.8) / nrow(tx))), 2),
  "0.65" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.65) / nrow(tx))), 2),
  "0.5" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.5) / nrow(tx))), 2)
)
```

% of reads which can be assigned to each taxonomic ranks

```{r}

tx <-taxData[rownames(dds),]
nc <- counts(dds, normalize = DNORM)
ac <- sum(nc)

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.8),]) / ac * 100))), 2),
  "0.65" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.65),]) / ac * 100))), 2),
  "0.5" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.5),]) / ac * 100))), 2)
)

```

## Abundance

```{r}
abundance_plot <- ggplot(
  data = as.data.frame(colData(dds)), 
  aes(x = site, y = copy_number, colour = cultivar, shape = planting_season)
) + geom_jitter() + 
  scale_colour_manual(values = cbPalette)

ggsave(
  filename = "bac_abundance.png", plot = abundance_plot, path = "figures/", 
  height = 20, width = 20, units = "cm"
)

abundance_plot

# Formula for ANOVA
formula <- update(DESIGN, copy_number ~ .)

abundance_anova <- aovp(formula, data = as.data.frame(colData(dds)))
summary(abundance_anova)
```

# Alpha diversity analysis

## Alpha diversity plot

```{r}

# plot alpha diversity - plot_alpha will convert normalised abundances to integer values

bac_alpha_plot <- plot_alpha(
  counts(dds,normalize = F), colData(dds),
  design = "cultivar", colour = "site",
  measures = c("Shannon", "Simpson"),
  type="box"
) + 
  scale_colour_manual(values = cbPalette) + 
  theme(axis.title.x =  element_blank()) + 
  ggtitle("Bacterial α-diversity") + 
  labs(colour = "Site")
  # facet_wrap(~planting_season)

ggsave(
  filename = "bac_alpha.png", plot = bac_alpha_plot, path = "figures/", 
  height = 20, width = 40, units = "cm"
)

bac_alpha_plot
```

## Permutation based anova on diversity index ranks

```{r}
# get the diversity index data
all_alpha_ord <- plot_alpha(
  counts(dds, normalize = F), colData(dds), design = "site", returnData = T
)

# join diversity indices and metadata
all_alpha_ord <- all_alpha_ord[
  as.data.table(colData(dds), keep.rownames = "Samples"), on = "Samples"
]

formula <- DESIGN
```

### Chao1

```{r}
setkey(all_alpha_ord, S.chao1)
all_alpha_ord[, measure := as.numeric(as.factor(S.chao1))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

### Shannon

```{r}
setkey(all_alpha_ord, shannon)
all_alpha_ord[, measure := as.numeric(as.factor(shannon))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

### Simpson

```{r}
setkey(all_alpha_ord, simpson)
all_alpha_ord[, measure := as.numeric(as.factor(simpson))]
summary(aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T))
```

# Beta diversity PCA/NMDS

## PCA 
```{r}

# perform PC decomposition of DES object
mypca <- des_to_pca(dds)

# to get pca plot axis into the same scale create a dataframe of PC scores multiplied by their variance
d <- t(data.frame(t(mypca$x) * mypca$percentVar))

formula = DESIGN
```

### Percent variation in first 4 PCs 
```{r}
pca_var <- data.frame(
  row.names = c("PC1", "PC2", "PC3", "PC4"),
  perc_var = round(mypca$percentVar[1:4] * 100, 3)
)

pca_var
```

### ANOVA of first 4 PCs
```{r} 
pca_summary <- apply(
  mypca$x[, 1:4], 2, 
  function(x){
    summary(aov(update(formula, x ~ .), data = as.data.frame(cbind(x, colData(dds)))))
  }
)

pca_summary
```

### Percent variation in first 4 PCs for each factor

```{r}
pcas <- list(
  PC1 = data.frame(unclass(pca_summary$PC1)),
  PC2 = data.frame(unclass(pca_summary$PC2)),
  PC3 = data.frame(unclass(pca_summary$PC3)),
  PC4 = data.frame(unclass(pca_summary$PC4))
)

pca_factors <- data.table(
  PCs = names(pcas),
  total_var = pca_var$perc_var,
  site_var = sapply(pcas, function(x) (x['site', 'Sum.Sq'] / sum(x['Sum.Sq'])) * 100),
  site_p = sapply(pcas, function(x) x['site', 'Pr..F.']),
  cultivar_var = sapply(pcas, function(x) (x['cultivar', 'Sum.Sq'] / sum(x['Sum.Sq'])) * 100),
  cultivar_p = sapply(pcas, function(x) x['cultivar', 'Pr..F.']),
  season_var = sapply(pcas, function(x) (x['planting_season', 'Sum.Sq'] / sum(x['Sum.Sq'])) * 100),
  season_p = sapply(pcas, function(x) x['planting_season', 'Pr..F.']),
  residuals_var = sapply(pcas, function(x) (x['Residuals', 'Sum.Sq'] / sum(x['Sum.Sq'])) * 100)
)

pca_factors
```

### PCA plot
```{r, fig.width=8,fig.height=5}

bac_pca_plot <- plotOrd(
  d,
  colData(dds),
  design = "cultivar",
  shape = "site",
  axes = c(1, 2),
  facet = "planting_season", 
  cbPalette = T,
  alpha = 0.75,
) #+ facet_wrap(~facet) 

ggsave(filename = "bac_pca_plot.png", plot = bac_pca_plot, path = "figures/")

bac_pca_plot
```

### PCA sum of squares (% var)

```{r}
sum_squares <- apply(mypca$x, 2 ,function(x) 
  summary(aov(update(formula, x ~ .), data = cbind(x, colData(dds))))[[1]][2]
)
sum_squares <- do.call(cbind, sum_squares)
x <- t(apply(sum_squares, 2, prop.table))
perVar <- x * mypca$percentVar
#colSums(perVar)
round(colSums(perVar) / sum(colSums(perVar)) * 100, 3)
```

## ADONIS

```{r}
vg <- vegdist(t(counts(dds, normalize = T)), method = "bray")
set.seed(sum(utf8ToInt("Hamish McLean")))
adonis2(update(formula, vg ~ .), colData(dds), permutations = 1000)
```

## NMDS ordination

```{r}
set.seed(sum(utf8ToInt("Hamish McLean")))
ord <- metaMDS(vg,trace=0) 
#sratmax=20000,maxit=20000,try = 177, trymax = 177

nmds <- scores(ord)

bac_nmds_plot <- plotOrd(
  nmds, colData(dds), design = Factor2, 
  shape = Factor1, alpha = 0.75, cbPalette = T
) + theme(text = element_text(size = 14))

ggsave(filename = "fun_nmds_plot.png", plot = bac_nmds_plot, path = "figures/")

bac_nmds_plot
```

### NMDS with phylum or class arrows

```{r} 
otus <- scores(ord,"species") 

taxmerge <-data.table(inner_join(data.table(OTU=rownames(otus),as.data.frame(otus)),data.table(OTU=rownames(taxData),taxData))) 
taxmerge$phy <- taxaConfVec(taxmerge[,c(-1:-3,-8)],conf=0.9,level=which(colnames(taxmerge[,c(-1:-3,-8)])=="phylum"))
taxmerge$cls <- taxaConfVec(taxmerge[,c(-1:-3,-8)],conf=0.9,level=which(colnames(taxmerge[,c(-1:-3,-8)])=="class")) 

phy <- taxmerge[,lapply(.SD,mean),by=phy,.SDcols=c("NMDS1","NMDS2")]
cls <- taxmerge[,lapply(.SD,mean),by=cls,.SDcols=c("NMDS1","NMDS2")]

bac_nmds_plot + geom_segment(inherit.aes = F,data=phy,aes(xend=NMDS1,yend=NMDS2,x=0,y=0),size=1.5,arrow=arrow()) + 
  geom_text(inherit.aes = F,data=phy,aes(x=NMDS1,y=(NMDS2+sign(NMDS2)*0.05),label=phy))

ggsave(filename = "fun_nmds_phy.png", plot = bac_nmds_plot, path = "figures/")
``` 

# ASV abundance

## Filter top ASVs

```{r Bac top ASVs}
# Extract normalised counts from DESeq object
nc <- counts(dds, normalize = T) %>% as.data.frame()

# Filter the top x abundant OTUs by the sum of their normalised counts
top_otus <- nc[order(rowSums(nc), decreasing = T)[1:DIFFOTU], ]

# Check that sample names match
identical(names(top_otus), rownames(colData))

# Extract taxonomic data for top OTUs
top_taxa <- taxData[rownames(top_otus), ]

# Log transform normalised counts
top_otus <- log10(top_otus + 1)
```

## Effect of design factors on top ASVs

Effect of site, cultivar, and planting season on abundance of top `r DIFFOTU` ASVs

```{r Bac ASV anova}
top_otu_data <- data.frame(t(top_otus))
top_otu_ids <- rownames(top_otus)
identical(rownames(top_otu_data), rownames(colData))

top_otu_data <- merge(top_otu_data, colData, by = 0) %>% column_to_rownames("Row.names")

otu_anova <- function(otu, formula, data) {
  a = data.frame(unclass(summary(aov(update(formula, paste(otu, "~ .")), data = data))))
  d = data.frame(
    OTU = otu,
    Taxonomy = taxData[otu, "rank"],
    site_var = a['site', 'Sum.Sq'] / sum(a$Sum.Sq) * 100,
    site_p = a['site', 'Pr..F.'],
    cultivar_var = a['cultivar', 'Sum.Sq'] / sum(a$Sum.Sq) * 100,
    cultivar_p = a['cultivar', 'Pr..F.'],
    season_var = a['planting_season', 'Sum.Sq'] / sum(a$Sum.Sq) * 100,
    season_p = a['planting_season', 'Pr..F.'],
    residuals_var = a['Residuals', 'Sum.Sq'] / sum(a$Sum.Sq) * 100
  )
  return(d)
}

formula <- DESIGN

otu_anova_results <- data.table(t(sapply(top_otu_ids, function(x) otu_anova(x, formula, top_otu_data))))

otu_anova_results_adjusted <- otu_anova_results %>% 
  mutate(
    site_p = p.adjust(site_p, method = "BH"),
    cultivar_p = p.adjust(cultivar_p, method = "BH"),
    season_p = p.adjust(season_p, method = "BH")
  )

otu_anova_results_adjusted

nrow(otu_anova_results_adjusted[otu_anova_results_adjusted$site_p < 0.05, ])
nrow(otu_anova_results_adjusted[otu_anova_results_adjusted$cultivar_p < 0.05, ])

otu_anova_results_adjusted[otu_anova_results_adjusted$cultivar_p < 0.05, ]
```
