---
title: "Root endophyte analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(comment = "#")
knitr::opts_chunk$set(fig.width = 9, fig.height = 9)
knitr::opts_chunk$set(error = TRUE)
```

<!-- #=============================================================================== -->
#       Load libraries
<!-- #=============================================================================== -->

```{r libraries}
## Load required libraries
library(DESeq2)
library(tidyverse)
library(data.table)
library(vegan)
library(lmPerm)
library(viridis)
library(grid)
library(gridExtra)
library(cowplot)
library(iNEXT)

# library(devtools)
# install_github("eastmallingresearch/Metabarcoding_pipeline/scripts")
# library(metafuncs)
```

<!-- #=============================================================================== -->
#       Functions and constants
<!-- #=============================================================================== -->

```{r constants}
ALPHA =      .1    # DESeq2 alpha value
OTUFILTER =  .001  # Remove OTUs with proportion of total reads below value
READFILTER = .05   # Will remove samples with read sum below sample_median_reads*READFILTER 
PAIREDONLY = F     # Will remove the pair of samples which fail the readfilter - probably only useful for DESeq separated by type NOTE removes pairs before DESeq object is created   
TAXCONF =    .60   # Sets the taxonomy confidence level to get "rank" in taxonomy files
TOPOTU =     10    # Number of Top OTUs for summary information

DNORM = F # Boolean for DeSeq2 normalisation

# graphics
DEVICE =     "png"
DPI =        1200
WIDTH =      9
HEIGHT =     9

# Model design
Factor1 = "trial"
Factor2 = "cultivar"
design = y ~ trial + planting_date * cultivar
```

```{r functions}
# colour blind palette
cbPalette <- c(
  "#000000", "#E69F00", "#56B4E9", "#009E73", 
  "#F0E442", "#0072B2", "#D55E00", "#CC79A7"
)

source("functions/rarefaction.R")
source("lauren_analysis/metabarcoding.R")
source("lauren_analysis/loadme.R")
```

<!-- #=============================================================================== -->
#       Load data
<!-- #=============================================================================== -->

```{r data}
metadata <- "sample_metadata.txt"

# Load
#ubiome_BAC <- loadData("data/BAC.otu_table.txt",metadata,"data/BAC.sintax.taxa",RHB="BAC")
#ubiome_FUN <- loadData("data/FUN.otu_table.txt",metadata,"data/FUN.sintax.taxa",RHB="FUN")

ubiome_BAC <- loadData("data/BAC.zotu_table.txt",metadata,"data/zBAC.sintax.taxa",RHB="BAC")
ubiome_FUN <- loadData("data/FUN.zotu_table.txt",metadata,"data/zFUN.sintax.taxa",RHB="FUN")
```

<!-- #=============================================================================== -->
#       Abundance normalisation
<!-- #=============================================================================== -->

OTU normalisation is performed using qPCR theoretical copy number data. 
The OTU counts are multiplied by the ratio of copy number:total OTUs for each sample.
The formula is: 
$$adjustedOTUs = OTUcount \times \frac{copyNumber}{totalOTUs}$$

```{r abundance}

abundance <- fread("mean_abundance.csv")

# Add sample ID to abundance data
abundance$ID <- paste0("HM", gsub("-", "", abundance$Sample))

# Add bacterial (16S) and fungal (ITS) abundance to ubiome BAC and FUN named lists
ubiome_BAC$abundance <- abundance[abundance$Target == "16S"]
ubiome_FUN$abundance <- abundance[abundance$Target == "ITS"]

#' Normalise count data
#' Normalise count data using qPCR theoretical copy number data
#' by multiplying the count data by the ratio of copy number:total OTUs
#' using the formula adjustedOTUs = OTUcount * copyNumber / totalOTUs.
#' `countData` is a matrix of OTU counts, `abundance` is a data frame of
#' qPCR copy number data, `ID` is the column name of the sample ID in both dataframes.
#' 'countData' is overwritten with the normalised data.
normaliseCountData <- function(data) {
  # Calculate total OTUs per sample
  totalOTUs <- apply(data$countData, 2, sum)
  totalOTUs <- data.frame("ID" = names(totalOTUs), "TotalOTUs" = totalOTUs, row.names = NULL)
  
  # Merge total OTUs with abundance data
  data[["abundance"]] <- merge(data$abundance, totalOTUs, by = "ID")

  # Calculate adjusted total OTUs
  data[["abundance"]] <- data$abundance %>%
    mutate(AdjustedTotalOTUs = MeanAdjustedTCN / TotalOTUs)

  # Save raw count data
  data$rawCountData <- data$countData

  # Multiply count data by adjusted total OTUs for each sample
  abundance = t(data.frame("AdjustedTotalOTUs" = data$abundance$AdjustedTotalOTUs, row.names = data$abundance$ID))
  data$countData<- data$rawCountData %>%
    mutate(across(everything(), ~ . * abundance[, cur_column()]))

  return(data)
}

ubiome_BAC <- normaliseCountData(ubiome_BAC)
ubiome_FUN <- normaliseCountData(ubiome_FUN)

identical(ubiome_FUN$rawCountData, ubiome_BAC$countData)

```

<!-- #=============================================================================== -->
#       Filter samples and OTUs
<!-- #=============================================================================== -->

```{r filter}
# Filter Plant, Chloroplast, and Eukaryote OTUs

# Fungi: Plantae OTUs
cat("Fungi:", length(grep("Plantae", ubiome_FUN$taxData$kingdom)), "Plantae OTUs\n")

# Bacteria: Chloroplast (Streptophyta) and Eukaryote OTUs
cat(
  "Bacteria:", length(grep("Streptophyta", ubiome_BAC$taxData$genus)), "Chloroplast OTUs;", 
  length(grep("Eukaryota", ubiome_BAC$taxData$kingdom)), "Eukaryote OTUs\n"
)

# Filter Chloroplast and Eukaryote
filt <- rownames(
  ubiome_BAC$taxData[
    grepl("Streptophyta", ubiome_BAC$taxData$genus) & 
    as.numeric(ubiome_BAC$taxData$g_conf) >= TAXCONF,
  ]
)

filt <- c(filt, rownames(ubiome_BAC$taxData[grep("Eukaryota", ubiome_BAC$taxData$kingdom), ]))

cat("Bacteria: removing", length(filt), "OTUs")

ubiome_BAC$taxData <- ubiome_BAC$taxData[!rownames(ubiome_BAC$taxData) %in% filt, ]
ubiome_BAC$countData <- ubiome_BAC$countData[!rownames(ubiome_BAC$countData) %in% filt, ]
```


<!-- #=============================================================================== -->
#       Create DEseq objects
<!-- #=============================================================================== -->
```{r DEseq}
# filtered for minimum of 1000 reads
ubiome_FUN$dds <- ubiom_to_des(ubiome_FUN, filter = expression(colSums(countData) >= 1000))
ubiome_BAC$dds <- ubiom_to_des(ubiome_BAC, filter = expression(colSums(countData) >= 1000))
```

<!-- #=============================================================================== -->
#       Sample rarefaction plots
<!-- #=============================================================================== -->        

```{r rarefaction}
invisible(mapply(assign, names(ubiome_BAC), ubiome_BAC, MoreArgs = list(envir = globalenv())))
rare_bac <- gfunc(as.data.frame(counts(dds)), as.data.frame(colData(dds)), "Bacteria ZOTU")
invisible(mapply(assign, names(ubiome_FUN), ubiome_FUN, MoreArgs = list(envir = globalenv())))
rare_fun <- gfunc(as.data.frame(counts(dds)), as.data.frame(colData(dds)), "Fungi ZOTU")

rarefaction_plots <- grid.arrange(
  rare_bac, rare_fun,
  left = textGrob(label = expression("Log"[10] * " aligned sequenecs"), rot = 90),
  bottom = "ZOTU count", nrow = 2
)

ggsave(filename = "rarefaction_plots.png", plot = rarefaction_plots, path = "figures/")

rarefaction_plots
```

<!-- #=============================================================================== -->
#      ***FUNGI***
<!-- #=============================================================================== -->

```{r}
# Fungi
invisible(mapply(assign, names(ubiome_FUN), ubiome_FUN, MoreArgs = list(envir = globalenv())))
```

<!-- #=============================================================================== -->
##      OTU and sample summary
<!-- #=============================================================================== -->

### Read and sample summary

```{r read_summary}
cat(
  "Raw reads","\n\n",
  "Total raw reads:\t\t", sum(countData),"\n",
  "Mean raw reads per sample:\t", mean(colSums(countData)),"\n",
  "Median raw reads per sample:\t", median(colSums(countData)),"\n",
  "Max raw reads per sample:\t", max(colSums(countData)),"\n",
  "Min raw reads per sample:\t", min(colSums(countData)),"\n\n"
)
#colSums(countData)

nct <- counts(dds,normalize = DNORM)
cat("Normalised reads","\n\n",
  "Total normalised reads:\t\t", sum(nct),"\n",
  "Mean normalised reads per sample:\t", mean(colSums(nct)),"\n",
  "Median normalised reads per sample:\t", median(colSums(nct)),"\n",
  "Min normalised reads per sample:\t", min(colSums(nct)),"\n",
  "Max normalised reads per sample:\t", max(colSums(nct)),"\n\n"
)
#round(colSums(counts(dds,normalize = DNORM)),0)
```

### OTU summary 

```{r otu_summary}
cat(
  "Total OTUs:\t\t", nrow(taxData),"\n\n",
  "Raw reads per OTU summary", "\n\n",
  "Mean raw reads per OTU:\t", mean(rowSums(countData)),"\n",
  "Median raw per OTU:\t\t", median(rowSums(countData)),"\n",
  "OTU raw Min reads:\t\t", min(rowSums(countData)),"\n",
  "OTU raw Max reads:\t\t", max(rowSums(countData)),"\n\n"
)

cat(
  "Normalised reads per OTU summary","\n\n",
  "Mean normalised reads per OTU:\t\t", mean(rowSums(nct)),"\n",
  "Median normalised reads per OTU:\t", median(rowSums(nct)),"\n",
  "OTU normalised Min reads:\t\t", min(rowSums(nct)),"\n",
  "OTU normalised Max reads:\t\t", max(rowSums(nct)),"\n\n"
)

y <- rowSums(nct)
y <- y[order(y,decreasing = T)]
# proportion
xy <- y/sum(y)

cat("Top " ,TOPOTU, "OTUs:\n")
data.frame(counts=y[1:TOPOTU],Prop=xy[1:TOPOTU],rank=taxData[names(y)[1:TOPOTU],]$rank)

```

<!-- #=============================================================================== -->
##          Taxonomy Summary
<!-- #=============================================================================== -->

### Taxonomy identifiable

Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank

```{r}

# Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank

tx <- copy(taxData)
setDT(tx)
cols <- names(tx)[9:15]

tx[,(cols):=lapply(.SD,as.factor),.SDcols=cols]

data.table(
  rank=c("kingdom","phylum","class","order","family","genus","species"),
  "0.8"=round(unlist(lapply(cols,function(col) sum(as.number(tx[[col]])>=0.8)/nrow(tx))),2),
  "0.65"=round(unlist(lapply(cols,function(col) sum(as.number(tx[[col]])>=0.65)/nrow(tx))),2),
  "0.5"=round(unlist(lapply(cols,function(col) sum(as.number(tx[[col]])>=0.5)/nrow(tx))),2)
)

```

% of reads which can be assigned to each taxonomic ranks

```{r}

tx <-taxData[rownames(dds),]
  nc <- counts(dds,normalize = DNORM)
ac <- sum(nc)

data.table(
  rank=c("kingdom","phylum","class","order","family","genus","species"),
  "0.8"=round(unlist(lapply(cols ,function(col)(sum(nc[which(as.numeric(tx[[col]])>=0.8),])/ac *100))),2),
  "0.65"=round(unlist(lapply(cols,function(col)(sum(nc[which(as.numeric(tx[[col]])>=0.65),])/ac *100))),2),
  "0.5"=round(unlist(lapply(cols,function(col)(sum(nc[which(as.numeric(tx[[col]])>=0.5),])/ac *100))),2)
)

```

<!-- #=============================================================================== -->
#       Alpha diversity analysis
<!-- #=============================================================================== -->

## Alpha diversity plot
```{r fun_alpha_diversity}

# plot alpha diversity - plot_alpha will convert normalised abundances to integer values

fun_alpha_plot <- plot_alpha(
  counts(dds, normalize = DNORM), colData(dds),
  design = "cultivar", colour = "trial",
  measures = c("Chao1", "Shannon", "Simpson", "Observed"),
  type = "box"
) + scale_colour_manual(values = cbPalette) + 
  theme(axis.title.x = element_blank()) +
  ggtitle("Fungal ZOTU α-diversity")

ggsave(
  filename = "fun_alpha_diversity.png", plot = fun_alpha_plot, path = "figures/", 
  height = 20, width = 40, units = "cm"
)

fun_alpha_plot
```

## Permutation based anova on diversity index ranks
```{r}
# get the diversity index data
all_alpha_ord <- plot_alpha(counts(dds,normalize = DNORM),colData(dds),design="trial",returnData=T)

# join diversity indices and metadata
all_alpha_ord <- all_alpha_ord[
  as.data.table(colData(dds), keep.rownames = "Samples"), 
  on = "Samples"
]

all_alpha_ord[, trial.block := as.factor(paste0(trial, block))]
design <- x ~ trial * planting_date * cultivar + trial / trial.block
```

### Chao1
```{r}
setkey(all_alpha_ord, S.chao1)
all_alpha_ord[, measure := as.numeric(as.factor(S.chao1))]
summary(aovp(update(design,measure~.),all_alpha_ord,seqs=T))
```

### Shannon
```{r}
setkey(all_alpha_ord,shannon)
all_alpha_ord[,measure:=as.numeric(as.factor(shannon))]
summary(aovp(update(design,measure~.),all_alpha_ord,seqs=T))
```  

### Simpson
```{r}
setkey(all_alpha_ord,simpson)
all_alpha_ord[,measure:=as.numeric(as.factor(shannon))]
summary(aovp(update(design,measure~.),all_alpha_ord,seqs=T))
```

<!-- #=============================================================================== -->
#       Filter data
<!-- #============================================================================ -->

```{r}
dds <- dds[rowSums(counts(dds, normalize = DNORM))>5,]
```
<!-- #=============================================================================== -->
#       Beta diversity PCA/NMDS
<!-- #=============================================================================== -->

## PCA 
```{r}
### PCA ###

# perform PC decomposition of DES object
mypca <- des_to_pca(dds)

# to get pca plot axis into the same scale create a dataframe of PC scores multiplied by their variance
d <-t(data.frame(t(mypca$x)*mypca$percentVar))
```

### Percent variation in first 4 PCs 
```{r}
round(mypca$percentVar[1:4],3)
```

### ANOVA of first 4 PCs
```{r} 
apply(mypca$x[,1:4],2,function(x){
  summary(aov(update(design,x~.),data=as.data.frame(cbind(x,colData(dds)))))
})
```

### PCA plot
```{r, fig.width=8,fig.height=5}

pca_plot <- plotOrd(d,
        colData(dds),
        design=Factor2,
        shape=Factor1,
        axes=c(1,2),
   #     facet="field_pair", 
        cbPalette=T,
        alpha=0.75,) #+ 
  #geom_line(aes(group=facet),alpha=0.25,linetype=3,colour="#000000") + 
  #theme(text = element_text(size=14))

ggsave(filename = "fun_pca_plot.png", plot = pca_plot, path = "figures/")
```

### PCA sum of squares (% var)
```{r}
sum_squares <- apply(mypca$x,2,function(x) 
  summary(aov(update(design,x~.),data=cbind(x,colData(dds))))[[1]][2]
)
sum_squares <- do.call(cbind,sum_squares)
x<-t(apply(sum_squares,2,prop.table))
perVar <- x * mypca$percentVar
#colSums(perVar)
round(colSums(perVar)/sum(colSums(perVar))*100,3)
```

## ADONIS
```{r}
vg <- vegdist(t(counts(dds,normalize = DNORM)),method="bray")
set.seed(sum(utf8ToInt("Hamish McLean")))
adonis(update(design,vg~.),colData(dds),permutations = 1000)

```

## NMDS ordination
```{r}
set.seed(sum(utf8ToInt("Hamish McLean")))
ord <- metaMDS(vg,trace=0) 
#sratmax=20000,maxit=20000,try = 177, trymax = 177

nmds <- scores(ord)

g <- plotOrd(nmds,colData(dds),design=Factor2,shape=Factor1,alpha=0.75,cbPalette=T)
g + theme(text=element_text(size=14))

ggsave(filename = "fun_nmds_plot.png", plot = g, path = "figures/")
```

### NMDS with phylum or class arrows 
```{r} 
otus <- scores(ord,"species") 

taxmerge <-data.table(inner_join(data.table(OTU=rownames(otus),as.data.frame(otus)),data.table(OTU=rownames(taxData),taxData))) 
taxmerge$phy <- taxaConfVec(taxmerge[,c(-1:-3,-8)],conf=0.9,level=which(colnames(taxmerge[,c(-1:-3,-8)])=="phylum"))
taxmerge$cls <- taxaConfVec(taxmerge[,c(-1:-3,-8)],conf=0.9,level=which(colnames(taxmerge[,c(-1:-3,-8)])=="class")) 

phy <- taxmerge[,lapply(.SD,mean),by=phy,.SDcols=c("NMDS1","NMDS2")]
cls <- taxmerge[,lapply(.SD,mean),by=cls,.SDcols=c("NMDS1","NMDS2")]

g + geom_segment(inherit.aes = F,data=phy,aes(xend=NMDS1,yend=NMDS2,x=0,y=0),size=1.5,arrow=arrow()) + 
 geom_text(inherit.aes = F,data=phy,aes(x=NMDS1,y=(NMDS2+sign(NMDS2)*0.05),label=phy)) 
``` 


<!-- #=============================================================================== -->
#       differential analysis
<!-- #=============================================================================== -->

## DESeq design 
```{r}

# p value for FDR cutoff
alpha <- 0.1

# add design to dds object
design(dds) <- design

# run model
dds <- DESeq(dds,parallel=F)

# build results table
res <- results(dds,alpha=alpha,contrast=c("Status","Diseased","Healthy"))

```

## Result summary

Rank is lowest taxonomic rank with >=0.65 confidence

### All samples
```{r}
summary(res)

# merge DESeq results with taxonomy
res.merge <- as.data.table(res,keep.rownames="OTU")[
  as.data.table(taxData,keep.rownames="OTU"),on="OTU"]

# print sig. results
res.merge[padj<=alpha,.(OTU,rank,
                        baseMean=round(baseMean,2),
                        FC=round(log2FoldChange,2),
                        padj=round(padj,4))][order(FC,decreasing = T),]

```

<!-- ### Write results -->
<!-- ```{r} -->

<!-- fwrite(res.merge,paste(RHB,"_DES.txt"),quote=F,na="",sep="\t") -->
<!-- fwrite(res2.merge,paste(RHB,"_DES_Paired.txt"),quote=F,na="",sep="\t") -->

<!-- ``` -->


#      ***BACTERIA***


<!-- #=============================================================================== -->
```{r}
# Bacteria
invisible(mapply(assign, names(ubiome_BAC), ubiome_BAC, MoreArgs=list(envir = globalenv())))

# add nested pair column
dds$field_pair <- as.factor(paste(dds$Field,dds$Pair,sep="_"))
colData$field_pair <- as.factor(paste(colData$Field,colData$Pair,sep="_"))

## collapse replicates
dds <- collapseReplicates(dds,groupby = paste0(dds$Status,dds$field_pair))
sizeFactors(dds) <- sizeFactors(estimateSizeFactors(dds))

## remove chloroplasts/mitochondria
dds <- dds[!rownames(dds)%in%c(rownames(taxData[taxData$rank=="Streptophyta(g)",]),"OTU3")]

## filter
keep <- c(which(duplicated(colData(dds)$field_pair,fromLast=T)),
          which(duplicated(colData(dds)$field_pair,fromLast=F)))

```

<!-- #=============================================================================== -->
#       Alpha diversity analysis
<!-- #=============================================================================== -->

## Alpha diversity plot
```{r}

# plot alpha diversity - plot_alpha will convert normalised abundances to integer values
bac_alpha_plot <- plot_alpha(
  counts(dds,normalize = DNORM), colData(dds),
  design = "cultivar", colour = "trial",
  measures = c("Chao1", "Shannon", "Simpson", "Observed"),
  type="box"
) + scale_colour_manual(values = cbPalette) + 
  theme(axis.title.x =  element_blank()) + 
  ggtitle("Bacterial ZOTU α-diversity")

ggsave(
  filename = "bac_alpha_diversity.png", plot = bac_alpha_plot, path = "figures/", 
  height = 20, width = 40, units = "cm"
)
```

## Permutation based anova on diversity index ranks
```{r}
# get the diversity index data
all_alpha_ord <- plot_alpha(counts(dds,normalize = DNORM),colData(dds),design="Status",returnData=T)

# join diversity indices and metadata
all_alpha_ord <- all_alpha_ord[as.data.table(colData(dds),keep.rownames="Samples"),
                               on="Samples"]

```

### Chao1
```{r}
setkey(all_alpha_ord,S.chao1)
all_alpha_ord[,measure:=as.numeric(as.factor(S.chao1))]
summary(aovp(update(design,measure~.),all_alpha_ord,seqs=T))
```

### Shannon
```{r}
setkey(all_alpha_ord,shannon)
all_alpha_ord[,measure:=as.numeric(as.factor(shannon))]
summary(aovp(update(design,measure~.),all_alpha_ord,seqs=T))
```  

### Simpson
```{r}
setkey(all_alpha_ord,simpson)
all_alpha_ord[,measure:=as.numeric(as.factor(shannon))]
summary(aovp(update(design,measure~.),all_alpha_ord,seqs=T))
```

<!-- #=============================================================================== -->
#       Filter data
<!-- #============================================================================ -->

```{r}
dds <- dds[rowSums(counts(dds, normalize = DNORM))>5,]
```
<!-- #=============================================================================== -->
#       Beta diversity PCA/NMDS
<!-- #=============================================================================== -->

## PCA 
```{r}
### PCA ###

# perform PC decomposition of DES object
mypca <- des_to_pca(dds)

# to get pca plot axis into the same scale create a dataframe of PC scores multiplied by their variance
d <-t(data.frame(t(mypca$x)*mypca$percentVar))
```

### Percent variation in first 4 PCs 
```{r}
round(mypca$percentVar[1:4],3)
```

### ANOVA of first 4 PCs
```{r} 
apply(mypca$x[,1:4],2,function(x){
  summary(aov(update(design,x~.),data=as.data.frame(cbind(x,colData(dds)))))
})
```

### PCA plot
```{r, fig.width=8,fig.height=5}

fun_pca_plot <- plotOrd(d,
        colData(dds),
        design=Factor2,
        shape=Factor1,
        axes=c(1,2),
   #     facet="field_pair", 
        cbPalette=T,
        alpha=0.75,) #+ 
  #geom_line(aes(group=facet),alpha=0.25,linetype=3,colour="#000000") + 
  #theme(text = element_text(size=14))

ggsave(filename = "bac_pca_plot.png", plot = fun_pca_plot, path = "figures/")
```

### PCA sum of squares (% var)
```{r}
sum_squares <- apply(mypca$x,2,function(x) 
  summary(aov(update(design,x~.),data=cbind(x,colData(dds))))[[1]][2]
)
sum_squares <- do.call(cbind,sum_squares)
x<-t(apply(sum_squares,2,prop.table))
perVar <- x * mypca$percentVar
#colSums(perVar)
round(colSums(perVar)/sum(colSums(perVar))*100,3)
```

## ADONIS
```{r}
vg <- vegdist(t(counts(dds,normalize = DNORM)),method="bray")
set.seed(sum(utf8ToInt("Hamish McLean")))
adonis(update(design,vg~.),colData(dds),permutations = 1000)

```

## NMDS ordination
```{r}
set.seed(sum(utf8ToInt("Hamish McLean")))
ord <- metaMDS(vg,trace=0) 
#sratmax=20000,maxit=20000,try = 177, trymax = 177

nmds <- scores(ord)

g <- plotOrd(nmds,colData(dds),design=Factor2,shape=Factor1,alpha=0.75,cbPalette=T)
g + theme(text=element_text(size=14))

ggsave(filename = "bac_nmds_plot.png", plot = g, path = "figures/")
```

### NMDS with phylum or class arrows 
```{r} 
otus <- scores(ord,"species") 

taxmerge <-data.table(inner_join(data.table(OTU=rownames(otus),as.data.frame(otus)),data.table(OTU=rownames(taxData),taxData))) 
taxmerge$phy <- taxaConfVec(taxmerge[,c(-1:-3,-8)],conf=0.9,level=which(colnames(taxmerge[,c(-1:-3,-8)])=="phylum"))
taxmerge$cls <- taxaConfVec(taxmerge[,c(-1:-3,-8)],conf=0.9,level=which(colnames(taxmerge[,c(-1:-3,-8)])=="class")) 

phy <- taxmerge[,lapply(.SD,mean),by=phy,.SDcols=c("NMDS1","NMDS2")]
cls <- taxmerge[,lapply(.SD,mean),by=cls,.SDcols=c("NMDS1","NMDS2")]

g + geom_segment(inherit.aes = F,data=phy,aes(xend=NMDS1,yend=NMDS2,x=0,y=0),size=1.5,arrow=arrow()) + 
 geom_text(inherit.aes = F,data=phy,aes(x=NMDS1,y=(NMDS2+sign(NMDS2)*0.05),label=phy)) 
``` 


<!-- #=============================================================================== -->
#       differential analysis
<!-- #=============================================================================== -->

## DESeq design 
```{r}

# p value for FDR cutoff
alpha <- 0.1

# add design to dds object
design(dds) <- design

# run model
dds <- DESeq(dds,parallel=F)

# build results table
res <- results(dds,alpha=alpha,contrast=c("Status","Diseased","Healthy"))

```

## Result summary

Rank is lowest taxonomic rank with >=0.65 confidence

### All samples
```{r}
summary(res)

# merge DESeq results with taxonomy
res.merge <- as.data.table(res,keep.rownames="OTU")[
  as.data.table(taxData,keep.rownames="OTU"),on="OTU"]

# print sig. results
res.merge[padj<=alpha,.(OTU,rank,
                        baseMean=round(baseMean,2),
                        FC=round(log2FoldChange,2),
                        padj=round(padj,4))][order(FC,decreasing = T),]

```

<!-- ### Write results -->
<!-- ```{r} -->

<!-- fwrite(res.merge,paste(RHB,"_DES.txt"),quote=F,na="",sep="\t") -->
<!-- fwrite(res2.merge,paste(RHB,"_DES_Paired.txt"),quote=F,na="",sep="\t") -->

<!-- ``` -->
