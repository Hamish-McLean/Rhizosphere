---
title: "Root endophyte analysis"
output: html_document
---

Built with R version  `r getRversion()`.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(comment = "#")
knitr::opts_chunk$set(fig.width = 9, fig.height = 9)
knitr::opts_chunk$set(error = TRUE)
```

## Setup

### Libraries

```{r libraries}
library(DESeq2)
library(tidyverse)
library(data.table)
library(vegan)
library(lmPerm)
library(viridis)
library(grid)
library(gridExtra)
library(cowplot)
library(iNEXT)
# library(car)
library(pscl)
library(DHARMa)
library(MASS)
# library(rcompanion)
library(ggpubr)

# library(devtools)
# install_github("eastmallingresearch/Metabarcoding_pipeline/scripts")
library(metafuncs)
```

### Functions and constants

```{r constants}
ALPHA =      0.1   # DESeq2 alpha value
OTUFILTER =  0.01  # Remove OTUs with proportion of total reads below value
READFILTER = 0.05  # Will remove samples with read sum below sample_median_reads*READFILTER 
PAIREDONLY = F     # Will remove the pair of samples which fail the readfilter - probably only useful for DESeq separated by type NOTE removes pairs before DESeq object is created   
TAXCONF =    0.80  # Sets the taxonomy confidence level to get "rank" in taxonomy files
TOPOTU =     10    # Number of Top OTUs for summary information
DIFFOTU =    200    # Number of Top OTUs for correlation analysis

# graphics
DEVICE =     "png"
DPI =        1200
WIDTH =      9
HEIGHT =     9

# Model design
Factor1 = "Site"
Factor2 = "Scion"
DESIGN = y ~ Site + Season + Scion
FULL_DESIGN = y ~ Site * Season * Scion
canker_design = "Cankers ~ Site * Season * Scion + "
```

```{r functions}
# colour blind palette
cbPalette <- c(
  "#000000", "#E69F00", "#56B4E9", "#009E73", 
  "#F0E442", "#0072B2", "#D55E00", "#CC79A7"
)

source("functions/metabarcoding.R")
source("functions/loadme.R")
source("functions/rarefaction.R")
```

## Load data

Bacterial and fungal ASV (ZOTU) tables, sample metadata, and taxonomy files are
loaded into named lists using the `loadData` function from Greg's `metafuncs` 
package.

```{r data}
metadata <- "sample_metadata.txt"

# Load data
ubiome_BAC <- loadData("data/BAC.zotu_table.txt",metadata,"data/zBAC.sintax.taxa",RHB="BAC")
ubiome_FUN <- loadData("data/FUN.zotu_table.txt",metadata,"data/zFUN.sintax.taxa",RHB="FUN")

# Rename site to Site and cultivar to Scion
ubiome_BAC$colData <- ubiome_BAC$colData %>% rename(location = site, Scion = cultivar)
ubiome_FUN$colData <- ubiome_FUN$colData %>% rename(location = site, Scion = cultivar)

# Correct for planting date month variability.
# March and April are replaced by spring, December by winter.
mutate_season <- function(data){
  data <- data %>%
    mutate(
      Season = case_when(
        planting_date %in% c("march", "april") ~ "Spring",
        planting_date %in% c("dec") ~ "Winter"
      )
    )
  return(data)
}

ubiome_BAC$colData <- mutate_season(ubiome_BAC$colData)
ubiome_FUN$colData <- mutate_season(ubiome_FUN$colData)

# Change sites Avalon -> A, Scripps -> B, and WWF -> C
mutate_site <- function(data){
  data <- data %>%
    mutate(
      Site = case_when(
        location == "Avalon" ~ "A",
        location == "Scripps" ~ "B",
        location == "WWF" ~ "C"
      )
    )
  return(data)
}

ubiome_BAC$colData <- mutate_site(ubiome_BAC$colData)
ubiome_FUN$colData <- mutate_site(ubiome_FUN$colData)
```

### Global removals

```{r}
# Sample "A2-7" removed due to missampling.
ubiome_BAC$colData <- ubiome_BAC$colData[!rownames(ubiome_BAC$colData) %in% "HMA27", ]
ubiome_BAC$countData <- ubiome_BAC$countData[, !colnames(ubiome_BAC$countData) %in% "HMA27"]
ubiome_FUN$colData <- ubiome_FUN$colData[!rownames(ubiome_FUN$colData) %in% "HMA27", ]
ubiome_FUN$countData <- ubiome_FUN$countData[, !colnames(ubiome_FUN$countData) %in% "HMA27"]
```

## Filter samples and OTUs

### Filtering taxa

Plantae taxa are filtered from fungal `taxData`.
Chloroplast and Eukaryote  taxa are filtered from bacterial `taxData`.
Corresponding OTUs are removed from `countData`.

```{r filter_taxa}
# Filter Plant, Chloroplast, and Eukaryote OTUs

# Fungi: Plantae OTUs
cat("Fungi:", length(grep("Plantae", ubiome_FUN$taxData$kingdom)), "Plantae OTUs\n")

# Bacteria: Chloroplast (Streptophyta) and Eukaryote OTUs
cat(
  "Bacteria:", length(grep("Streptophyta", ubiome_BAC$taxData$genus)), "Chloroplast OTUs;", 
  length(grep("Eukaryota", ubiome_BAC$taxData$kingdom)), "Eukaryote OTUs\n"
)

# Filter Chloroplast and Eukaryote
filt <- rownames(
  ubiome_BAC$taxData[
    grepl("Streptophyta", ubiome_BAC$taxData$genus) & 
    as.numeric(ubiome_BAC$taxData$g_conf) >= TAXCONF,
  ]
)

filt <- c(filt, rownames(ubiome_BAC$taxData[grep("Eukaryota", ubiome_BAC$taxData$kingdom), ]))

cat("Bacteria: removing", length(filt), "OTUs")

ubiome_BAC$taxData <- ubiome_BAC$taxData[!rownames(ubiome_BAC$taxData) %in% filt, ]
ubiome_BAC$countData <- ubiome_BAC$countData[!rownames(ubiome_BAC$countData) %in% filt, ]
```

### Filtering samples

Plot rarefaction curves.

Remove samples with read count below `r READFILTER * 100` % of median.

```{r filter_samples, eval = FALSE}
invisible(mapply(assign, names(ubiome_BAC), ubiome_BAC, MoreArgs = list(envir = globalenv())))
rare_bac <- gfunc(countData, colData, "Bacteria")
# rare_bac <- gfunc(as.data.frame(counts(dds)), as.data.frame(colData(dds)), "Bacteria ZOTU")
invisible(mapply(assign, names(ubiome_FUN), ubiome_FUN, MoreArgs = list(envir = globalenv())))
rare_fun <- gfunc(countData, colData, "Fungi")
# rare_fun <- gfunc(as.data.frame(counts(dds)), as.data.frame(colData(dds)), "Fungi ZOTU")

rarefaction_plots <- grid.arrange(
  rare_bac, rare_fun,
  left = textGrob(label = expression("log"[10] * " aligned sequences"), rot = 90),
  bottom = "ASV count", nrow = 2
)

ggsave(filename = "rarefaction_plots.png", plot = rarefaction_plots, path = "figures/")

rarefaction_plots

# Fungi
med <- median(colSums(ubiome_FUN$countData))
filt <- !colSums(ubiome_FUN$countData) > med * READFILTER
cat("Fungi: ",sum(filt),"sample(s) removed\n")

# Bacteria
med <- median(colSums(ubiome_BAC$countData))
filt <- !colSums(ubiome_BAC$countData) > med * READFILTER
cat("Bacteria: ",sum(filt),"sample(s) removed\n")
```

### Filter ASVs

#### ASV read count

Number of ASVs which account for 50 %, 80 %, and 99 % of total reads.

```{r}
asv_propotions <- function(countData, proportion){
  i <- sum(countData)
  y <- rowSums(countData)
  y <- y[order(y, decreasing = T)]
  asvs <- length(y[(cumsum(y) / i <= proportion)])
  return(asvs)
}

proportions <- c(0.5, 0.9, 0.99, 1)

top_asvs <- data.table(
  "proportion" = proportions,
  "Fungi" = lapply(proportions, function(x) asv_propotions(ubiome_FUN$countData, x)),
  "Bacteria" = lapply(proportions, function(x) asv_propotions(ubiome_BAC$countData, x))
)

top_asvs
```

#### Filter ASVs

Remove ASVs with read count below `r OTUFILTER * 100` % of total reads.

```{r filter_reads}
# Fungi
keep <- filter_otus(ubiome_FUN$countData, OTUFILTER)
cat("Fungi: removing", nrow(ubiome_FUN$countData) - length(keep), "OTUs\n")

ubiome_FUN$taxData <- ubiome_FUN$taxData[rownames(ubiome_FUN$taxData) %in% keep,]
ubiome_FUN$countData <- ubiome_FUN$countData[rownames(ubiome_FUN$countData) %in% keep,]

# Bacteria
keep <-  filter_otus(ubiome_BAC$countData, OTUFILTER)
cat("Bacteria: removing", nrow(ubiome_BAC$countData) - length(keep), "OTUs")

ubiome_BAC$taxData <- ubiome_BAC$taxData[rownames(ubiome_BAC$taxData) %in% keep,]
ubiome_BAC$countData <- ubiome_BAC$countData[rownames(ubiome_BAC$countData) %in% keep,]
```

## Absolute abundance normalisation

OTU normalisation is performed using qPCR theoretical copy number data.
Copy number is calculated per mg of root sample from the qPCR data.

### Prepare qPCR abundance data

```{r abundance}
abundance <- fread("mean_abundance.csv")

# Add sample ID to abundance data
abundance$id <- paste0("HM", gsub("-", "", abundance$Sample))
# abundance$id <- abundance$Sample
abundance$copy_number <- abundance$MeanAdjustedTCN_mg
abundance$log_copy_number <- log10(abundance$copy_number)

# Add bacterial (16S) and fungal (ITS) abundance to ubiome BAC and FUN named lists
ubiome_FUN$abundance <- abundance[abundance$Target == "ITS"] %>%
  column_to_rownames(var = "id")
ubiome_BAC$abundance <- abundance[abundance$Target == "16S"] %>%
  column_to_rownames(var = "id")

# Merge copy number from abundance with colData
ubiome_FUN$colData <- merge(
  ubiome_FUN$colData, 
  ubiome_FUN$abundance[, c("Target", "copy_number", "log_copy_number")], 
  by = 0
) %>% column_to_rownames(var = "Row.names")
ubiome_BAC$colData <- merge(
  ubiome_BAC$colData, 
  ubiome_BAC$abundance[, c("Target", "copy_number", "log_copy_number")], 
  by = 0
) %>% column_to_rownames(var = "Row.names")
```

#### Remove outliers

```{r}
# Detect outliers with std > threshold from the median
detect_outliers <- function(x, val, threshold, na.rm = TRUE) {
  med_x <- median(x[[val]], na.rm = na.rm)
  sd_x <- sd(x[[val]], na.rm = na.rm)
  outliers <- x[x[[val]] > (med_x + threshold * sd_x) | x[[val]] < (med_x - threshold * sd_x), ]
  return(outliers)
}

outliers_FUN <- detect_outliers(ubiome_FUN$abundance, "MeanAdjustedTCN_mg", 3)
outliers_BAC <- detect_outliers(ubiome_BAC$abundance, "MeanAdjustedTCN_mg", 3)

# Remove samples with copy number > 3 std from the median
outliers <- rownames(outliers_FUN)
ubiome_FUN$abundance <- ubiome_FUN$abundance[!rownames(ubiome_FUN$abundance) %in% outliers, ]
ubiome_FUN$countData <- ubiome_FUN$countData[, !colnames(ubiome_FUN$countData) %in% outliers]
ubiome_FUN$colData <- ubiome_FUN$colData[!rownames(ubiome_FUN$colData) %in% outliers, ]

cat("Fungi: removing", length(outliers), "outlier(s)\n")
```

Sample A1-3 is removed from the fungal data due to abnormally high copy number.

## Canker count data

Canker count data for sampled trees only.

```{r canker data}
# Canker count data for sampled trees only

canker_data <- fread("canker_data.csv", select = c(1:5, 7:34))

# Remove spaces from column names and convert to lowercase
colnames(canker_data) <- tolower(gsub(" ", "_", colnames(canker_data)))

# Codify site names, add planting season and total canker count for timepoint 4
canker_data <- mutate(
  canker_data,
  Site = case_when(
    site == "Avalon" ~ "A",
    site == "Scripps" ~ "B",
    site == "WWF" ~ "C"
  ),
  Season = case_when(
    planting_date %in% c("March", "April") ~ "Spring",
    planting_date %in% c("Dec") ~ "Winter"
  ),
  total_cankers = a4 + b4 + c4 + d4 + e4
)

# Identify samples with missing values
missing <- unique(canker_data[!complete.cases(canker_data), code])

# Also remove sample A2-7 due to missampling
missing <- c(missing, "HMA27")

# Remove missing samples from canker data
canker_data <- canker_data[!canker_data$code %in% missing, ]

# Verify that there are two trees for each sample
canker_data %>% group_by(code) %>% summarise(n = n()) %>% filter(n != 2)

# Sum of total cankers for each pair of trees with matching code
cankers <- canker_data %>% 
  group_by(code) %>% 
  summarise(
    Site = first(Site),
    Season = first(Season),
    Scion = first(cultivar),
    Cankers = sum(total_cankers)
  ) %>% 
  column_to_rownames("code")

# Add total canker count to colData for both FUN and BAC
ubiome_FUN$colData <- merge(
  ubiome_FUN$colData, 
  cankers["Cankers"], 
  by = 0,
  all.x = T
) %>% column_to_rownames("Row.names")

ubiome_BAC$colData <- merge(
  ubiome_BAC$colData, 
  cankers["Cankers"], 
  by = 0,
  all.x = T
) %>% column_to_rownames("Row.names")
```

Summary stats

```{r}
# png("figures/hist.png", width = 800, height = 600)
# hist(cankers$Cankers, breaks = 20, main = "Total canker count", xlab = "Total canker count")
# dev.off()

cankers_hist <- ggdensity(
  cankers, x = "Cankers", fill = "Site", facet.by = "Site", ncol = 1,
  add = "mean", rug = T, palette = cbPalette,
  title = "Total canker count", xlab = "Total canker count"
)

cankers_hist

ggsave(filename = "cankers_hist.png", plot = cankers_hist, path = "figures/")

cankers_box <- ggboxplot(
  cankers, x = "Site", y = "Cankers", palette = cbPalette,
  color = "Scion", add = "jitter", legend = "top", 
  title = "Total canker count", xlab = "Site", ylab = "Total canker count"
)

cankers_box

ggsave(filename = "cankers_box.png", plot = cankers_box, path = "figures/")

cankers_bar <- ggbarplot(
  cankers, x = "Site", y = "Cankers", fill = "Scion", 
  palette = cbPalette, add = "mean_se", position = position_dodge(0.8),
  title = "Total canker count", xlab = "Site", ylab = "Total canker count"
)

cankers_bar

ggsave(filename = "cankers_bar.png", plot = cankers_bar, path = "figures/")
```

GLM

```{r canker GLM}
# Effect of Site, Scion, and Season on canker count

# Formula
formula <- update(FULL_DESIGN, Cankers ~ .)
# formula <- Cankers ~ Site + Season + Scion + site:Season + site:Scion + Season:Scion

# Log-linear model
canker_lm <- lm(update(FULL_DESIGN, log(Cankers + 1) ~ .), data = cankers)

par(mfrow = c(2, 2))
plot(canker_lm)

# Residual checking
res <- resid(canker_lm, type = "pearson")

# Poisson model
canker_poisson <- glm(formula, data = cankers, family = "poisson")

poisson_plot <- plot(simulateResiduals(canker_poisson), title = "Poisson model")

# Model overdispersed

# Negative binomial model
canker_negbin <- glm.nb(formula, data = cankers)

sim <- simulateResiduals(canker_negbin)

plot(sim, title = "Negative binomial model")

# canker_model_plots <- ggarrange(lm_plot, poisson_plot, negbin_plot, ncol = 3)

# ggsave(filename = "canker_model_plots.png", plot = canker_model_plots, path = "figures/")

# png("figures/canker_residuals.png", width = 800, height = 600)
# plot(sim)
# dev.off()

testZeroInflation(sim)

nagelkerke(canker_negbin)

# Model good fit

canker_anova <- anova(canker_negbin, test = "Chisq") %>% data.frame()
total_deviance <- sum(canker_anova$Deviance, na.rm = T) + tail(canker_anova$Resid..Dev, 1)
canker_anova$Perc..Dev <- canker_anova$Deviance / total_deviance * 100

canker_anova
```

## Create DESeq objects

```{r DESeq}
# Make sure countData and colData still match, if they do, create DESeq objects, if not throw error
if(identical(colnames(ubiome_FUN$countData), rownames(ubiome_FUN$colData))) {
  # Create DESeq object
  ubiome_FUN$dds <- ubiom_to_des(ubiome_FUN)
  print("FUN DESeq object created")
} else {
  stop("FUN countData and colData do not match")
}

if(identical(colnames(ubiome_BAC$countData), rownames(ubiome_BAC$colData))) {
  # Create DESeq object
  ubiome_BAC$dds <- ubiom_to_des(ubiome_BAC)
  print("BAC DESeq object created")
} else {
  stop("BAC countData and colData do not match")
}
```

## Abundance normalisation

Absolute abundance normalisation using DESeq2 size factors.

Values are centred around the mean of the copy number.

```{r}
# Normalise count data using DESeq2 size factors

ubiome_FUN$dds$sizeFactor <- ubiome_FUN$dds$copy_number / mean(ubiome_FUN$dds$copy_number)
ubiome_BAC$dds$sizeFactor <- ubiome_BAC$dds$copy_number / mean(ubiome_BAC$dds$copy_number)
```

<!-- #=============================================================================== -->
# **Fungi**
<!-- #=============================================================================== -->

```{r}
# Unpack fungi data
invisible(mapply(assign, names(ubiome_FUN), ubiome_FUN, MoreArgs = list(envir = globalenv())))
```

## OTU and sample summary

### Read and sample summary

```{r read_summary}
cat(
  "Raw reads", "\n\n",
  "Total raw reads:\t\t", sum(countData), "\n",
  "Mean raw reads per sample:\t", mean(colSums(countData)), "\n",
  "Median raw reads per sample:\t", median(colSums(countData)), "\n",
  "Max raw reads per sample:\t", max(colSums(countData)), "\n",
  "Min raw reads per sample:\t", min(colSums(countData)), "\n\n"
)
#colSums(countData)

nct <- counts(dds, normalize = T)
cat("Normalised reads", "\n\n",
  "Total normalised reads:\t\t", sum(nct), "\n",
  "Mean normalised reads per sample:\t", mean(colSums(nct)), "\n",
  "Median normalised reads per sample:\t", median(colSums(nct)), "\n",
  "Min normalised reads per sample:\t", min(colSums(nct)), "\n",
  "Max normalised reads per sample:\t", max(colSums(nct)), "\n\n"
)
#round(colSums(counts(dds,normalize = T)),0)
```

### OTU summary 

```{r otu_summary}
cat(
  "Total OTUs:\t\t", nrow(taxData),"\n\n",
  "Raw reads per OTU summary", "\n\n",
  "Mean raw reads per OTU:\t", mean(rowSums(countData)),"\n",
  "Median raw per OTU:\t\t", median(rowSums(countData)),"\n",
  "OTU raw Min reads:\t\t", min(rowSums(countData)),"\n",
  "OTU raw Max reads:\t\t", max(rowSums(countData)),"\n\n"
)

cat(
  "Normalised reads per OTU summary","\n\n",
  "Mean normalised reads per OTU:\t\t", mean(rowSums(nct)),"\n",
  "Median normalised reads per OTU:\t", median(rowSums(nct)),"\n",
  "OTU normalised Min reads:\t\t", min(rowSums(nct)),"\n",
  "OTU normalised Max reads:\t\t", max(rowSums(nct)),"\n\n"
)

y <- rowSums(nct)
y <- y[order(y, decreasing = T)]
# proportion
xy <- y / sum(y)

cat("Top " ,TOPOTU, "OTUs:\n")
data.frame(counts = y[1:TOPOTU], proportion = xy[1:TOPOTU], rank = taxData[names(y)[1:TOPOTU],]$rank)
```

## Taxonomy Summary

### Taxonomy identifiable

Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank.

```{r}

# Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank

tx <- copy(taxData)
setDT(tx)
cols <- names(tx)[9:15]

tx[, (cols) := lapply(.SD, as.factor), .SDcols = cols]

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.8) / nrow(tx))), 2),
  "0.65" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.65) / nrow(tx))), 2),
  "0.5" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.5) / nrow(tx))), 2)
)
```

% of reads which can be assigned to each taxonomic ranks

```{r}

tx <-taxData[rownames(dds),]
nc <- counts(dds, normalize = T)
ac <- sum(nc)

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.8),]) / ac * 100))), 2),
  "0.65" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.65),]) / ac * 100))), 2),
  "0.5" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.5),]) / ac * 100))), 2)
)

```

## Abundance

Plot copy number for each sample grouped by site, Scion, and Season.
Test the effect of site, Scion, and Season on copy number using ANOVA.

```{r}
# abundance_plot <- ggplot(
#   data = as.data.frame(colData(dds)), 
#   aes(x = site, y = log_copy_number, colour = Scion, shape = Season)
# ) + geom_jitter() + 
#   scale_colour_manual(values = cbPalette)

fun_abundance_box <- ggboxplot(
  data = as.data.frame(colData(dds)), x = "Site", y = "log_copy_number", 
  color = "Scion", add = "jitter", legend = "top", 
  title = "Fungal abundance", xlab = "Site", ylab = "log10 copy number"
)

ggsave(
  filename = "fun_abundance.png", plot = fun_abundance_box, path = "figures/", 
  height = 20, width = 20, units = "cm"
)

fun_abundance_box

fun_abundance_bar <- ggbarplot(
  data = as.data.frame(colData(dds)), x = "Season", y = "log_copy_number", 
  fill = "Site", add = "mean_se", 
  palette = cbPalette, position = position_dodge(0.8),
  title = "(a) Fungal abundance", xlab = "Planting Season", ylab = "Mean copy number (log10)"
) + guides(fill = guide_legend(title = "Site"))

ggsave(
  filename = "fun_abundance_bar.png", plot = fun_abundance_bar, path = "figures/", 
  height = 20, width = 20, units = "cm"
)

fun_abundance_bar

# Formula for ANOVA
formula <- update(FULL_DESIGN, log_copy_number ~ .)

abundance_anova <- aov(formula, data = as.data.frame(colData(dds)))

# Normality check
par(mfrow = c(2, 2))
plot(abundance_anova)

png("figures/fun_abundance_norm.png", width = 800, height = 600)
par(mfrow = c(2, 2))
plot(abundance_anova)
dev.off()

# Results
summary(abundance_anova)
abundance_results <- abundance_anova %>% summary() %>% unclass() %>% data.frame()
total_variance <- sum(abundance_results$Sum.Sq)
abundance_results$Perc.Var <- abundance_results$Sum.Sq / total_variance * 100

abundance_results
```

## Alpha diversity analysis

### Alpha diversity plot

```{r fun_alpha_diversity}

# plot alpha diversity - plot_alpha will convert normalised abundances to integer values

fun_alpha_plot <- plot_alpha(
  counts(dds, normalize = F), colData(dds),
  design = "Scion", colour = "Site",
  measures = c("Shannon", "Simpson"),
  type = "bar"
) + scale_colour_manual(values = cbPalette) + 
  theme(axis.title.x = element_blank()) +
  ggtitle("Fungal α-diversity")

ggsave(
  filename = "fun_alpha.png", plot = fun_alpha_plot, path = "figures/", 
  height = 20, width = 40, units = "cm"
)

fun_alpha_plot
```

### Permutation based anova on diversity index ranks

```{r}
# get the diversity index data
all_alpha_ord <- plot_alpha(
  counts(dds, normalize = F),
  colData(dds),
  returnData = T
)

# join diversity indices and metadata
all_alpha_ord <- all_alpha_ord[
  as.data.table(colData(dds), keep.rownames = "Samples"), 
  on = "Samples"
]

fun_alpha <- all_alpha_ord

formula <- FULL_DESIGN # x ~ Site * Season * Scion + Site / Site.block
```

#### Chao1

```{r}
setkey(all_alpha_ord, S.chao1)
all_alpha_ord[, measure := as.numeric(as.factor(S.chao1))]
result <- aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T)
summary(result)
df <- result %>% summary() %>% unclass() %>% data.frame()
total_variance <- sum(df$R.Sum.Sq)
df$Perc.Var <- df$R.Sum.Sq / total_variance * 100
df
```

#### Shannon

```{r}
setkey(all_alpha_ord, shannon)
all_alpha_ord[, measure := as.numeric(as.factor(shannon))]
result <- aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T)
summary(result)
df <- result %>% summary() %>% unclass() %>% data.frame()
total_variance <- sum(df$R.Sum.Sq)
df$Perc.Var <- df$R.Sum.Sq / total_variance * 100
df
```

#### Simpson

```{r}
setkey(all_alpha_ord, simpson)
all_alpha_ord[, measure := as.numeric(as.factor(simpson))]
result <- aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T)
summary(result)
df <- result %>% summary() %>% unclass() %>% data.frame()
total_variance <- sum(df$R.Sum.Sq)
df$Perc.Var <- df$R.Sum.Sq / total_variance * 100
df
```

## Beta diversity PCA/NMDS

### PCA

```{r}
# Perform PC decomposition of DES object
mypca <- des_to_pca(dds)

# To get pca plot axis into the same scale create a dataframe of PC scores multiplied by their variance
fun_pca <- t(data.frame(t(mypca$x) * mypca$percentVar))

formula = FULL_DESIGN
```

#### Percent variation in first 10 PCs 

```{r}
# Cumulative percentage of variance explained
pca_cum_var <- data.frame(
  cumulative = cumsum(mypca$percentVar * 100),
  no = 1:length(mypca$percentVar)
)

# Plot cumulative percentage of variance explained
fun_cum_pca <- ggline(
  pca_cum_var, x = "no", y = "cumulative", plot_type = "l",
  xlab = "Number of PCs", ylab = "Cumulative % variance explained",
  title = "Fungi: cumulative % variance explained by PCs"
)
ggsave(filename = "fun_cum_pca.png", plot = fun_cum_pca, path = "figures/",)
fun_cum_pca

# Number of PCs to include
n <- 10

pca_var <- data.frame(
  row.names = paste0("PC", 1:n),
  perc_var = round(mypca$percentVar[1:n] * 100, 1)
)

pca_var
```

#### ANOVA of first 10 PCs

```{r} 
pca_summary <- apply(
  mypca$x[, 1:n], 2, 
  function(x){
    summary(aov(update(formula, x ~ .), data = as.data.frame(cbind(x, colData(dds)))))
  }
)

pca_summary
```

#### Percent variation in first 10 PCs for each factor

```{r}
pcas <- lapply(pca_summary, function(i) data.frame(unclass(i)))

pca_factors <- data.table(
  PCs = names(pcas),
  total_var = pca_var$perc_var,
  site_var = sapply(pcas, function(x) (x['Site ', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100)),
  site_p = sapply(pcas, function(x) x['Site ', 'Pr..F.']),
  cultivar_var = sapply(pcas, function(x) (x['Scion', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100)),
  cultivar_p = sapply(pcas, function(x) x['Scion', 'Pr..F.']),
  season_var = sapply(pcas, function(x) (x['Season ', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100)),
  season_p = sapply(pcas, function(x) x['Season ', 'Pr..F.']),
  site_cultivar_var = sapply(pcas, function(x) (x['Site:Scion', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100)),
  site_cultivar_p = sapply(pcas, function(x) x['Site:Scion', 'Pr..F.']),
  site_season_var = sapply(pcas, function(x) (x['Site:Season ', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100)),
  site_season_p = sapply(pcas, function(x) x['Site:Season ', 'Pr..F.']),
  residuals_var = sapply(pcas, function(x) (x['Residuals', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100))
)

pca_factors
```

#### PCA plot

```{r, fig.width = 8, fig.height = 5}
fun_pca_plot <- plotOrd(
  fun_pca,
  colData(dds),
  design = "Site",
  shapes = "Season",
  axes = c(1, 2),
  cbPalette = T,
  alpha = 0.75,
) # + facet_wrap(~facet) 
#   geom_line(aes(group=facet),alpha=0.25,linetype=3,colour="#000000") + 
#   theme(text = element_text(size=14))

ggsave(filename = "fun_pca_plot.png", plot = fun_pca_plot, path = "figures/")

fun_pca_plot
```

#### PCA sum of squares (% var)

```{r}
sum_squares <- apply(mypca$x, 2 ,function(x) 
  summary(aov(update(formula, x ~ .), data = cbind(x, colData(dds))))[[1]][2]
)
sum_squares <- do.call(cbind, sum_squares)
x <- t(apply(sum_squares, 2, prop.table))
perVar <- x * mypca$percentVar
#colSums(perVar)
round(colSums(perVar) / sum(colSums(perVar)) * 100, 3)
```

### ADONIS

```{r}
# Calculate Bray-Curtis distance matrix
vg <- vegdist(t(counts(dds, normalize = T)), method = "bray")

formula <- update(FULL_DESIGN, vg ~ .)

set.seed(sum(utf8ToInt("Hamish McLean")))
result <- adonis2(formula, colData(dds), permutations = 1000)
result
df <- result %>% data.frame()
df$Perc.Var <- df$SumOfSqs / df["Total", "SumOfSqs"] * 100
df
```

### NMDS ordination

```{r}
set.seed(sum(utf8ToInt("Hamish McLean")))
ord <- metaMDS(vg,trace=0) 
#sratmax=20000,maxit=20000,try = 177, trymax = 177

fun_nmds <- scores(ord)

fun_nmds_plot <- plotOrd(
  fun_nmds, colData(dds), 
  design = "Site", 
  shape = "Season", 
  alpha = 0.75, cbPalette = T
) #+ theme(text = element_text(size = 14))

ggsave(filename = "fun_nmds_plot.png", plot = fun_nmds_plot, path = "figures/")

fun_nmds_plot
```

## ASV abundance

### Filter top ASVs

```{r top ASVs}
# Extract normalised counts from DESeq object
asv_counts <- round(counts(dds, normalize = T), 0) %>% as.data.frame()

# Sum ASV counts across samples
total_asv_counts <- rowSums(asv_counts)

# Sort ASVs by abundance
total_asv_counts <- total_asv_counts[order(total_asv_counts, decreasing = T)]

# Caculate cumulative percentage
cumulative <- data.frame(
  cumulative = cumsum(total_asv_counts) / sum(total_asv_counts) * 100,
  no = seq_along(total_asv_counts)
)

# Plot cumulative percentage of ASVs
fun_cum_asv <- ggline(
  data = cumulative, x = "no", y = "cumulative", 
  plot_type = "l", palette = cbPalette,
  title = "Cumulative percentage of fungal ASVs", xlab = "Number of ASVs", 
  ylab = "Cumulative percentage of reads"
)
ggsave(filename = "fun_cum_asv.png", plot = fun_cum_asv, path = "figures/")
fun_cum_asv

# Find the number of ASVs that account for 50%, 80%, and 99% of total reads
cat(
  "Number of ASVs that account for 50%, 80%, and 99% of total reads", "\n\n",
  "50%:", sum(cumulative <= 50), "\n",
  "80%:", sum(cumulative <= 80), "\n",
  "99%:", sum(cumulative <= 99), "\n"
)

# Find the cumulative percentage accounted for by top x ASVs
cat(
  "Percentage of total reads accounted for by the top 100, 200,and 500 ASVs:", "\n\n",
  "100:", round(cumulative[cumulative$no == 100, "cumulative"], 1) , "\n",
  "200:", round(cumulative[cumulative$no == 200, "cumulative"], 1) , "\n",
  "500:", round(cumulative[cumulative$no == 500, "cumulative"], 1) , "\n"
)

# Average ASV counts in order
mean_asv_counts <- rowMeans(asv_counts)
mean_asv_counts <- mean_asv_counts[order(mean_asv_counts, decreasing = T)]

# Plot read count distribution
fun_asv_counts <- ggline(
  data = data.frame(ASV = seq_along(mean_asv_counts), counts = mean_asv_counts),
  x = "ASV", y = "counts", plot_type = "l",
  title = "Fungal ASV read count distribution", xlab = "ASV", ylab = "Mean read count"
)
ggsave(filename = "fun_asv_counts.png", plot = fun_asv_counts, path = "figures/")
fun_asv_counts

# Number of ASVs with mean read count > 100, 200, and 500
cat(
  "Number of ASVs with mean read count > 100, 200, and 500", "\n\n",
  "100:", sum(rowMeans(asv_counts) > 100), "\n",
  "200:", sum(rowMeans(asv_counts) > 200), "\n",
  "500:", sum(rowMeans(asv_counts) > 500), "\n"
)
```

```{r}
# Filter the top x abundant OTUs by the sum of their normalised counts
# top_asvs <- asv_counts[order(rowSums(asv_counts), decreasing = T)[1:DIFFOTU], ]

# Filter ASVs with mean read count > 100
top_asvs <- asv_counts[rowMeans(asv_counts) > 100, ]

# Check that sample names match
identical(names(top_asvs), rownames(colData))

# Extract taxonomic data for top OTUs
top_taxa <- taxData[rownames(top_asvs), ]

# Log transform normalised counts
# top_asvs <- log10(top_asvs + 1)

top_asv_data <- data.frame(t(top_asvs))
top_asv_ids <- rownames(top_asvs)

# Check that sample names match
identical(rownames(top_asv_data), rownames(colData))

# Add sample metadata to top OTU data
top_asv_data <- merge(top_asv_data, colData, by = 0) %>% column_to_rownames("Row.names")
```

### Effect of design factors on abundance of top ASVs

Effect of Site, Scion, and planting season on abundance of top `r DIFFOTU` ASVs

```{r ASV anova}
# ANOVA of top ASVs
otu_lm_anova <- function(otu, formula, data) {
  f = update(formula, paste0("log(", otu, " + 1) ~ ."))
  a = aov(f, data = data) %>% summary() %>% unclass() %>% data.frame()
  total_var = sum(a$Sum.Sq)
  d = data.frame(
    OTU = otu,
    Taxonomy = taxData[otu, "rank"],
    site_var = a['Site ', 'Sum.Sq'] / total_var * 100,
    site_p = a['Site ', 'Pr..F.'],
    cultivar_var = a['Scion', 'Sum.Sq'] / total_var * 100,
    cultivar_p = a['Scion', 'Pr..F.'],
    season_var = a['Season ', 'Sum.Sq'] / total_var * 100,
    season_p = a['Season ', 'Pr..F.'],
    site_cultivar_var = a['Site:Scion', 'Sum.Sq'] / total_var * 100,
    site_cultivar_p = a['Site:Scion', 'Pr..F.'],
    site_season_var = a['Site:Season ', 'Sum.Sq'] / total_var * 100,
    site_season_p = a['Site:Season ', 'Pr..F.'],
    residuals_var = a['Residuals', 'Sum.Sq'] / total_var * 100
  )
  return(d)
}

# Negative binomial regression model
otu_negbin_anova <- function(otu, formula, data) {
  f = update(formula, paste0(otu, " ~ ."))
  m = glm.nb(f, data = data)
  a = anova(m, test = "Chisq") %>% data.frame()
  total_deviance = sum(a$Deviance, na.rm = T) + tail(a$Resid..Dev, 1)
  d = data.frame(
    OTU = otu,
    Taxonomy = taxData[otu, "rank"],
    site_var = a['Site', 'Deviance'] / total_deviance * 100,
    site_p = a['Site', 'Pr..Chi.'],
    cultivar_var = a['Scion', 'Deviance'] / total_deviance * 100,
    cultivar_p = a['Scion', 'Pr..Chi.'],
    season_var = a['Season', 'Deviance'] / total_deviance * 100,
    season_p = a['Season', 'Pr..Chi.']
  )
  return(d)
}

formula <- FULL_DESIGN

# Full design model does not converge
# formula <- y ~ site + Scion + Season + site:Scion + site:Season

# formula <- DESIGN

# otu_lm_anova(top_asv_ids[1], formula, top_asv_data)

otu_anova_results <- sapply(
  top_asv_ids, function(x) otu_lm_anova(x, formula, top_asv_data)
) %>% t() %>% data.table()

otu_anova_results_adjusted <- otu_anova_results %>% 
  mutate(
    site_p = p.adjust(site_p, method = "BH"),
    cultivar_p = p.adjust(cultivar_p, method = "BH"),
    season_p = p.adjust(season_p, method = "BH"),
    site_cultivar_p = p.adjust(site_cultivar_p, method = "BH"),
    site_season_p = p.adjust(site_season_p, method = "BH")
  )

cat(
  "Number of ASVs with statistically significant (*P* < 0.05) adjusted p-values", "\n\n",
  "Site:", nrow(otu_anova_results_adjusted[site_p < 0.05, ]), "\n",
  "Scion:", nrow(otu_anova_results_adjusted[cultivar_p < 0.05, ]), "\n",
  "Season:", nrow(otu_anova_results_adjusted[season_p < 0.05, ]), "\n",
  "Site:Scion:", nrow(otu_anova_results_adjusted[site_cultivar_p < 0.05, ]), "\n",
  "Site:Season:", nrow(otu_anova_results_adjusted[site_season_p < 0.05, ]), "\n\n"
)

otu_anova_results_adjusted[cultivar_p < 0.05, ]
otu_anova_results_adjusted[season_p < 0.05, ]
```

## Canker counts

### Effect of ASV abundance on canker count

```{r}
# Filter out samples with missing canker count
top_asv_data <- top_asv_data[complete.cases(top_asv_data$Cankers), ]

# ANOVA of top ASVs with canker count
asv_canker_anova <- function(otu, data) {
  f = paste0(canker_design, otu)
  m = glm.nb(f, data = data)
  a = anova(m, test = "Chisq") %>% data.frame()
  total_deviance = sum(a$Deviance, na.rm = T) + tail(a$Resid..Dev, 1)
  d = data.frame(
    OTU = otu,
    Taxonomy = taxData[otu, "rank"],
    coef = m$coefficients[otu],
    var = a[otu, 'Deviance'] / total_deviance * 100,
    p = a[otu, 'Pr..Chi.']
  )
  return(d)
}

# asv_canker_anova(top_asv_ids[1], top_asv_data)

# Effect of ASV abundance on canker count for top ASVs
asv_canker_results <- data.table(t(sapply(top_asv_ids, function(x) asv_canker_anova(x, top_asv_data))))

# Adjust p-values for multiple testing
asv_canker_results$p_adjusted <- p.adjust(asv_canker_results$p, method = "BH")

# Summary of ASVs with statistically significant (*P* < 0.05) adjusted p-values
cat(
  nrow(asv_canker_results[p_adjusted < 0.05, ]), 
  "ASVs have statistically significant (*P* < 0.05) adjusted p-values"
)
asv_canker_results[p_adjusted < 0.05, ]
```

### Effect of α-diversity on canker count

```{r}
# ANOVA of α-diversity with canker count

measures <- c("shannon", "simpson")

# ANOVA of α-diversity with canker count
alpha_canker_anova <- function(measure, data) {
  f = paste0(canker_design, measure)
  m = glm.nb(f, data = data)
  a = anova(m, test = "Chisq") %>% data.frame()
  total_deviance = sum(a$Deviance, na.rm = T) + tail(a$Resid..Dev, 1)
  d = data.frame(
    measure = measure,
    coef = m$coefficients[measure],
    var = a[measure, 'Deviance'] / total_deviance * 100,
    p = a[measure, 'Pr..Chi.']
  )
  return(d)
}

# Effect of α-diversity on canker count for each measure
alpha_canker_results <- data.table(t(sapply(measures, function(x) alpha_canker_anova(x, all_alpha_ord))))

alpha_canker_results
```

### Effect of β-diversity on canker count

```{r}
no_pcs <- 4

# Merge PC scores with canker data
pc_scores <- merge(colData, data.frame(mypca$x[, 1:no_pcs]), by = "row.names") %>% 
  column_to_rownames("Row.names")

pcs <- tail(colnames(pc_scores), no_pcs)

# ANOVA of β-diversity with canker count
beta_canker_anova <- function(pc, data) {
  f = paste0(canker_design, pc)
  m = glm.nb(f, data = data)
  a = anova(m, test = "Chisq") %>% data.frame()
  total_deviance = sum(a$Deviance, na.rm = T) + tail(a$Resid..Dev, 1)
  d = data.frame(
    PC = pc,
    coef = m$coefficients[pc],
    var = a[pc, 'Deviance'] / total_deviance * 100,
    p = a[pc, 'Pr..Chi.']
  )
  return(d)
}

# Effect of β-diversity on canker count for each PC
beta_canker_results <- data.table(t(sapply(pcs, function(x) beta_canker_anova(x, pc_scores))))

beta_canker_results
```

<!-- #=============================================================================== -->
# **Bacteria**
<!-- #=============================================================================== -->

```{r}
# Unpack bacteria data
invisible(mapply(assign, names(ubiome_BAC), ubiome_BAC, MoreArgs = list(envir = globalenv())))
```

## OTU and sample summary

### Read and sample summary

```{r}
cat(
  "Raw reads", "\n\n",
  "Total raw reads:\t\t", sum(countData), "\n",
  "Mean raw reads per sample:\t", mean(colSums(countData)), "\n",
  "Median raw reads per sample:\t", median(colSums(countData)), "\n",
  "Max raw reads per sample:\t", max(colSums(countData)), "\n",
  "Min raw reads per sample:\t", min(colSums(countData)), "\n\n"
)
#colSums(countData)

nct <- counts(dds, normalize = T)
cat("Normalised reads", "\n\n",
  "Total normalised reads:\t\t", sum(nct), "\n",
  "Mean normalised reads per sample:\t", mean(colSums(nct)), "\n",
  "Median normalised reads per sample:\t", median(colSums(nct)), "\n",
  "Min normalised reads per sample:\t", min(colSums(nct)), "\n",
  "Max normalised reads per sample:\t", max(colSums(nct)), "\n\n"
)
#round(colSums(counts(dds,normalize = T)),0)
```

### OTU summary 

```{r}
cat(
  "Total OTUs:\t\t", nrow(taxData),"\n\n",
  "Raw reads per OTU summary", "\n\n",
  "Mean raw reads per OTU:\t", mean(rowSums(countData)),"\n",
  "Median raw per OTU:\t\t", median(rowSums(countData)),"\n",
  "OTU raw Min reads:\t\t", min(rowSums(countData)),"\n",
  "OTU raw Max reads:\t\t", max(rowSums(countData)),"\n\n"
)

cat(
  "Normalised reads per OTU summary","\n\n",
  "Mean normalised reads per OTU:\t\t", mean(rowSums(nct)),"\n",
  "Median normalised reads per OTU:\t", median(rowSums(nct)),"\n",
  "OTU normalised Min reads:\t\t", min(rowSums(nct)),"\n",
  "OTU normalised Max reads:\t\t", max(rowSums(nct)),"\n\n"
)

y <- rowSums(nct)
y <- y[order(y, decreasing = T)]
# proportion
xy <- y/sum(y)

cat("Top ", TOPOTU, "OTUs:\n")
data.frame(counts = y[1:TOPOTU], proportion = xy[1:TOPOTU], rank = taxData[names(y)[1:TOPOTU],]$rank)
```

## Taxonomy Summary

### Taxonomy identifiable

Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank

```{r}

# Proportion of OTUs which can be assigned (with the given confidence) at each taxonomic rank

tx <- copy(taxData)
setDT(tx)
cols <- names(tx)[9:15]

tx[, (cols) := lapply(.SD, as.factor), .SDcols = cols]

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.8) / nrow(tx))), 2),
  "0.65" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.65) / nrow(tx))), 2),
  "0.5" = round(unlist(lapply(cols, function(col) sum(as.number(tx[[col]]) >= 0.5) / nrow(tx))), 2)
)
```

% of reads which can be assigned to each taxonomic ranks

```{r}

tx <-taxData[rownames(dds),]
nc <- counts(dds, normalize = T)
ac <- sum(nc)

data.table(
  rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
  "0.8" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.8),]) / ac * 100))), 2),
  "0.65" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.65),]) / ac * 100))), 2),
  "0.5" = round(unlist(lapply(cols, function(col)(sum(nc[which(as.numeric(tx[[col]]) >= 0.5),]) / ac * 100))), 2)
)

```

## Abundance

```{r}
abundance_plot <- ggplot(
  data = as.data.frame(colData(dds)), 
  aes(x = Site, y = log_copy_number, colour = Scion, shape = Season)
) + geom_jitter() + 
  scale_colour_manual(values = cbPalette)

abundance_plot <- ggboxplot(
  data = as.data.frame(colData(dds)), x = "Site", y = "log_copy_number", 
  color = "Scion", add = "jitter", legend = "top", 
  title = "Bacterial abundance", xlab = "Site", ylab = "log10 copy number"
)

ggsave(
  filename = "bac_abundance.png", plot = abundance_plot, path = "figures/", 
  height = 20, width = 20, units = "cm"
)

abundance_plot

# Formula for ANOVA
formula <- update(FULL_DESIGN, log_copy_number ~ .)

abundance_anova <- aov(formula, data = as.data.frame(colData(dds)))

# Normality check
par(mfrow = c(2, 2))
plot(abundance_anova)

png("figures/fun_abundance_norm.png", width = 800, height = 600)
par(mfrow = c(2, 2))
plot(abundance_anova)
dev.off()

# Results
summary(abundance_anova)
abundance_results <- abundance_anova %>% summary() %>% unclass() %>% data.frame()
total_variance <- sum(abundance_results$Sum.Sq)
abundance_results$Perc.Var <- abundance_results$Sum.Sq / total_variance * 100

abundance_results
```

## Alpha diversity analysis

### Alpha diversity plot

```{r}

# plot alpha diversity - plot_alpha will convert normalised abundances to integer values

bac_alpha_plot <- plot_alpha(
  counts(dds,normalize = F), colData(dds),
  design = "Scion", colour = "Site",
  measures = c("Shannon", "Simpson"),
  type="box"
) + 
  scale_colour_manual(values = cbPalette) + 
  theme(axis.title.x =  element_blank()) + 
  ggtitle("Bacterial α-diversity")

abundance_plot <- ggboxplot(
  data = as.data.frame(colData(dds)), x = "Site", y = "log_copy_number", 
  color = "Scion", add = "jitter", legend = "top", 
  title = "Fungal abundance", xlab = "Site", ylab = "log10 copy number"
)

ggsave(
  filename = "bac_alpha.png", plot = bac_alpha_plot, path = "figures/", 
  height = 20, width = 40, units = "cm"
)

bac_alpha_plot
```

### Permutation based anova on diversity index ranks

```{r}
# get the diversity index data
all_alpha_ord <- plot_alpha(
  counts(dds, normalize = F), colData(dds), design = "Site", returnData = T
)

# join diversity indices and metadata
all_alpha_ord <- all_alpha_ord[
  as.data.table(colData(dds), keep.rownames = "Samples"), on = "Samples"
]

bac_alpha <- all_alpha_ord

formula <- FULL_DESIGN
```

#### Chao1

```{r}
setkey(all_alpha_ord, S.chao1)
all_alpha_ord[, measure := as.numeric(as.factor(S.chao1))]
result <- aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T)
summary(result)
df <- result %>% summary() %>% unclass() %>% data.frame()
total_variance <- sum(df$R.Sum.Sq)
df$Perc.Var <- df$R.Sum.Sq / total_variance * 100
df
```

#### Shannon

```{r}
setkey(all_alpha_ord, shannon)
all_alpha_ord[, measure := as.numeric(as.factor(shannon))]
result <- aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T)
summary(result)
df <- result %>% summary() %>% unclass() %>% data.frame()
total_variance <- sum(df$R.Sum.Sq)
df$Perc.Var <- df$R.Sum.Sq / total_variance * 100
df
```

#### Simpson

```{r}
setkey(all_alpha_ord, simpson)
all_alpha_ord[, measure := as.numeric(as.factor(simpson))]
result <- aovp(update(formula, measure ~ .), all_alpha_ord, seqs = T)
summary(result)
df <- result %>% summary() %>% unclass() %>% data.frame()
total_variance <- sum(df$R.Sum.Sq)
df$Perc.Var <- df$R.Sum.Sq / total_variance * 100
df
```

## Beta diversity PCA/NMDS

### PCA 
```{r}
# perform PC decomposition of DES object
mypca <- des_to_pca(dds)

# to get pca plot axis into the same scale create a dataframe of PC scores multiplied by their variance
bac_pca <- t(data.frame(t(mypca$x) * mypca$percentVar))

formula = FULL_DESIGN
```

#### Percent variation in first 10 PCs 
```{r}
# Cumulative percentage of variance explained
pca_cum_var <- data.frame(
  cumulative = cumsum(mypca$percentVar * 100),
  no = 1:length(mypca$percentVar)
)

# Plot cumulative percentage of variance explained
bac_cum_pca <- ggline(
  pca_cum_var, x = "no", y = "cumulative", plot_type = "l",
  xlab = "Number of PCs", ylab = "Cumulative % variance explained",
  title = "Bacteria: cumulative % variance explained by PCs"
)
ggsave(filename = "bac_cum_pca.png", plot = bac_cum_pca, path = "figures/",)
bac_cum_pca

# Number of PCs to include
n <- 10

pca_var <- data.frame(
  row.names = paste0("PC", 1:n),
  perc_var = round(mypca$percentVar[1:n] * 100, 1)
)

pca_var
```

#### ANOVA of first 10 PCs
```{r} 
pca_summary <- apply(
  mypca$x[, 1:n], 2, 
  function(x){
    summary(aov(update(formula, x ~ .), data = as.data.frame(cbind(x, colData(dds)))))
  }
)

pca_summary
```

#### Percent variation in first 10 PCs for each factor

```{r}
pcas <- lapply(pca_summary, function(i) data.frame(unclass(i)))

pca_factors <- data.table(
  PCs = names(pcas),
  total_var = pca_var$perc_var,
  site_var = sapply(pcas, function(x) (x['Site ', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100)),
  site_p = sapply(pcas, function(x) x['Site ', 'Pr..F.']),
  cultivar_var = sapply(pcas, function(x) (x['Scion', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100)),
  cultivar_p = sapply(pcas, function(x) x['Scion', 'Pr..F.']),
  season_var = sapply(pcas, function(x) (x['Season ', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100)),
  season_p = sapply(pcas, function(x) x['Season ', 'Pr..F.']),
  site_cultivar_var = sapply(pcas, function(x) (x['Site:Scion', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100)),
  site_cultivar_p = sapply(pcas, function(x) x['Site:Scion', 'Pr..F.']),
  site_season_var = sapply(pcas, function(x) (x['Site:Season ', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100)),
  site_season_p = sapply(pcas, function(x) x['Site:Season ', 'Pr..F.']),
  residuals_var = sapply(pcas, function(x) (x['Residuals', 'Sum.Sq'] / sum(x['Sum.Sq']) * 100))
)

pca_factors
```

#### PCA plot
```{r, fig.width=8,fig.height=5}

bac_pca_plot <- plotOrd(
  bac_pca,
  colData(dds),
  design = "Site",
  shape = "Season",
  axes = c(1, 2),
  # facet = "Season", 
  cbPalette = T,
  alpha = 0.75,
) #+ facet_wrap(~facet)

ggsave(filename = "bac_pca_plot.png", plot = bac_pca_plot, path = "figures/")

bac_pca_plot
```

#### PCA sum of squares (% var)

```{r}
sum_squares <- apply(mypca$x, 2 ,function(x) 
  summary(aov(update(formula, x ~ .), data = cbind(x, colData(dds))))[[1]][2]
)
sum_squares <- do.call(cbind, sum_squares)
x <- t(apply(sum_squares, 2, prop.table))
perVar <- x * mypca$percentVar
#colSums(perVar)
round(colSums(perVar) / sum(colSums(perVar)) * 100, 3)
```

### ADONIS

```{r}
# Calculate Bray-Curtis distance matrix
vg <- vegdist(t(counts(dds, normalize = T)), method = "bray")

formula <- update(FULL_DESIGN, vg ~ .)

set.seed(sum(utf8ToInt("Hamish McLean")))
result <- adonis2(formula, colData(dds), permutations = 1000)
result
df <- result %>% data.frame()
df$Perc.Var <- df$SumOfSqs / df["Total", "SumOfSqs"] * 100
df
```

### NMDS ordination

```{r}
set.seed(sum(utf8ToInt("Hamish McLean")))
ord <- metaMDS(vg,trace=0) 
#sratmax=20000,maxit=20000,try = 177, trymax = 177

bac_nmds <- scores(ord)

bac_nmds_plot <- plotOrd(
  bac_nmds, colData(dds), 
  design = "Site", 
  shape = "Season", 
  alpha = 0.75, cbPalette = T
) #+ theme(text = element_text(size = 14))

ggsave(filename = "fun_nmds_plot.png", plot = bac_nmds_plot, path = "figures/")

bac_nmds_plot
```

## ASV abundance

### Filter top ASVs

```{r Bac top ASVs}
# Extract normalised counts from DESeq object
asv_counts <- counts(dds, normalize = T) %>% as.data.frame()

# Sum ASV counts across samples
total_asv_counts <- rowSums(asv_counts)

# Sort ASVs by abundance
total_asv_counts <- total_asv_counts[order(total_asv_counts, decreasing = T)]

# Caculate cumulative percentage
cumulative <- data.frame(
  cumulative = cumsum(total_asv_counts) / sum(total_asv_counts) * 100,
  no = seq_along(total_asv_counts)
)

# Plot cumulative percentage of ASVs
bac_cum_asv <- ggline(
  data = cumulative, x = "no", y = "cumulative", 
  plot_type = "l", palette = cbPalette,
  title = "Cumulative percentage of bacterial ASVs", xlab = "Number of ASVs", 
  ylab = "Cumulative percentage of reads"
)
ggsave(filename = "bac_cum_asv.png", plot = bac_cum_asv, path = "figures/")
bac_cum_asv

# Find the number of ASVs that account for 50%, 80%, and 99% of total reads
cat(
  "Number of ASVs that account for 50%, 80%, and 99% of total reads", "\n\n",
  "50%:", sum(cumulative <= 50), "\n",
  "80%:", sum(cumulative <= 80), "\n",
  "99%:", sum(cumulative <= 99), "\n"
)

# Find the cumulative percentage accounted for by top x ASVs
cat(
  "Percentage of total reads accounted for by the top 100, 200,and 500 ASVs:", "\n\n",
  "100:", round(cumulative[cumulative$no == 100, "cumulative"], 1) , "\n",
  "200:", round(cumulative[cumulative$no == 200, "cumulative"], 1) , "\n",
  "500:", round(cumulative[cumulative$no == 500, "cumulative"], 1) , "\n"
)

# Average ASV counts in order
mean_asv_counts <- rowMeans(asv_counts)
mean_asv_counts <- mean_asv_counts[order(mean_asv_counts, decreasing = T)]

# Plot read count distribution
bac_asv_counts <- ggline(
  data = data.frame(ASV = seq_along(mean_asv_counts), counts = mean_asv_counts),
  x = "ASV", y = "counts", plot_type = "l",
  title = "Bacterial ASV read count distribution", xlab = "ASV", ylab = "Mean read count"
)
ggsave(filename = "bac_asv_counts.png", plot = bac_asv_counts, path = "figures/")
bac_asv_counts

# Number of ASVs with mean read count > 100, 200, and 500
cat(
  "Number of ASVs with mean read count > 100, 200, and 500", "\n\n",
  "100:", sum(rowMeans(asv_counts) > 100), "\n",
  "200:", sum(rowMeans(asv_counts) > 200), "\n",
  "500:", sum(rowMeans(asv_counts) > 500), "\n"
)
```

```{r}
# Filter the top x abundant OTUs by the sum of their normalised counts
# top_asvs <- asv_counts[order(rowSums(asv_counts), decreasing = T)[1:DIFFOTU], ]

# Filter ASVs with mean read count > 100
top_asvs <- asv_counts[rowMeans(asv_counts) > 100, ]

# Check that sample names match
identical(names(top_asvs), rownames(colData))

# Extract taxonomic data for top OTUs
top_taxa <- taxData[rownames(top_asvs), ]

# Log transform normalised counts
top_asvs <- log10(top_asvs + 1)

top_asv_data <- data.frame(t(top_asvs))
top_asv_ids <- rownames(top_asvs)
identical(rownames(top_asv_data), rownames(colData))

top_asv_data <- merge(top_asv_data, colData, by = 0) %>% column_to_rownames("Row.names")
```

### Effect of design factors on top ASVs

Effect of Site, Scion, and planting season on abundance of top `r DIFFOTU` ASVs

```{r Bac ASV anova}
# ANOVA of top ASVs
otu_lm_anova <- function(otu, formula, data) {
  f = update(formula, paste0("log(", otu, " + 1) ~ ."))
  a = aov(f, data = data) %>% summary() %>% unclass() %>% data.frame()
  total_var = sum(a$Sum.Sq)
  d = data.frame(
    OTU = otu,
    Taxonomy = taxData[otu, "rank"],
    site_var = a['Site ', 'Sum.Sq'] / total_var * 100,
    site_p = a['Site ', 'Pr..F.'],
    cultivar_var = a['Scion', 'Sum.Sq'] / total_var * 100,
    cultivar_p = a['Scion', 'Pr..F.'],
    season_var = a['Season ', 'Sum.Sq'] / total_var * 100,
    season_p = a['Season ', 'Pr..F.'],
    site_cultivar_var = a['Site:Scion', 'Sum.Sq'] / total_var * 100,
    site_cultivar_p = a['Site:Scion', 'Pr..F.'],
    site_season_var = a['Site:Season ', 'Sum.Sq'] / total_var * 100,
    site_season_p = a['Site:Season ', 'Pr..F.'],
    residuals_var = a['Residuals', 'Sum.Sq'] / total_var * 100
  )
  return(d)
}

# Negative binomial regression model
otu_negbin_anova <- function(otu, formula, data) {
  f = update(formula, paste0(otu, " ~ ."))
  m = glm.nb(f, data = data)
  a = anova(m, test = "Chisq") %>% data.frame()
  total_deviance = sum(a$Deviance, na.rm = T) + tail(a$Resid..Dev, 1)
  d = data.frame(
    OTU = otu,
    Taxonomy = taxData[otu, "rank"],
    site_var = a['Site', 'Deviance'] / total_deviance * 100,
    site_p = a['Site', 'Pr..Chi.'],
    cultivar_var = a['Scion', 'Deviance'] / total_deviance * 100,
    cultivar_p = a['Scion', 'Pr..Chi.'],
    season_var = a['Season', 'Deviance'] / total_deviance * 100,
    season_p = a['Season', 'Pr..Chi.']
  )
  return(d)
}

formula <- FULL_DESIGN

otu_anova_results <- sapply(
  top_asv_ids, function(x) otu_lm_anova(x, formula, top_asv_data)
) %>% t() %>% data.table()

otu_anova_results_adjusted <- otu_anova_results %>% 
  mutate(
    site_p = p.adjust(site_p, method = "BH"),
    cultivar_p = p.adjust(cultivar_p, method = "BH"),
    season_p = p.adjust(season_p, method = "BH")
  )

cat(
  "Number of ASVs with statistically significant (*P* < 0.05) adjusted p-values", "\n\n",
  "Site:", nrow(otu_anova_results_adjusted[site_p < 0.05, ]), "\n",
  "Scion:", nrow(otu_anova_results_adjusted[cultivar_p < 0.05, ]), "\n",
  "Season:", nrow(otu_anova_results_adjusted[season_p < 0.05, ]), "\n",
  "Site:Scion:", nrow(otu_anova_results_adjusted[site_cultivar_p < 0.05, ]), "\n",
  "Site:Season:", nrow(otu_anova_results_adjusted[site_season_p < 0.05, ]), "\n\n"
)

otu_anova_results_adjusted[cultivar_p < 0.05, ]
otu_anova_results_adjusted[season_p < 0.05, ]
```

## Canker counts

### Effect of ASV abundance on canker count

```{r}
# Filter out samples with missing canker count
top_asv_data <- top_asv_data[complete.cases(top_asv_data$Cankers), ]

# ANOVA of top ASVs with canker count
asv_canker_anova <- function(otu, data) {
  f = paste0(canker_design, otu)
  m = glm.nb(f, data = data)
  a = anova(m, test = "Chisq") %>% data.frame()
  total_deviance = sum(a$Deviance, na.rm = T) + tail(a$Resid..Dev, 1)
  d = data.frame(
    OTU = otu,
    Taxonomy = taxData[otu, "rank"],
    coef = m$coefficients[otu],
    var = a[otu, 'Deviance'] / total_deviance * 100,
    p = a[otu, 'Pr..Chi.']
  )
  return(d)
}

# Effect of ASV abundance on canker count for top ASVs
asv_canker_results <- data.table(t(sapply(top_asv_ids, function(x) asv_canker_anova(x, top_asv_data))))

# Adjust p-values for multiple testing
asv_canker_results$p_adjusted <- p.adjust(asv_canker_results$p, method = "BH")

# Summary of ASVs with statistically significant (*P* < 0.05) adjusted p-values
nrow(asv_canker_results[asv_canker_results$p_adjusted < 0.05, ])
asv_canker_results[asv_canker_results$p_adjusted < 0.05, ]
```

### Effect of α-diversity on canker count

```{r}
# ANOVA of α-diversity with canker count

measures <- c("shannon", "simpson")

# ANOVA of α-diversity with canker count
alpha_canker_anova <- function(measure, data) {
  f = paste0(canker_design, measure)
  m = glm.nb(f, data = data)
  a = anova(m, test = "Chisq") %>% data.frame()
  total_deviance = sum(a$Deviance, na.rm = T) + tail(a$Resid..Dev, 1)
  d = data.frame(
    measure = measure,
    coef = m$coefficients[measure],
    var = a[measure, 'Deviance'] / total_deviance * 100,
    p = a[measure, 'Pr..Chi.']
  )
  return(d)
}

# Effect of α-diversity on canker count for each measure
alpha_canker_results <- data.table(t(sapply(measures, function(x) alpha_canker_anova(x, all_alpha_ord))))

alpha_canker_results
```

### Effect of β-diversity on canker count

```{r}
no_pcs <- 4

# Merge PC scores with canker data
pc_scores <- merge(colData, data.frame(mypca$x[, 1:no_pcs]), by = "row.names") %>% 
  column_to_rownames("Row.names")

pcs <- tail(colnames(pc_scores), no_pcs)

# ANOVA of β-diversity with canker count
beta_canker_anova <- function(pc, data) {
  f = paste0(canker_design, pc)
  m = glm.nb(f, data = data)
  a = anova(m, test = "Chisq") %>% data.frame()
  total_deviance = sum(a$Deviance, na.rm = T) + tail(a$Resid..Dev, 1)
  d = data.frame(
    PC = pc,
    coef = m$coefficients[pc],
    var = a[pc, 'Deviance'] / total_deviance * 100,
    p = a[pc, 'Pr..Chi.']
  )
  return(d)
}

# Effect of β-diversity on canker count for each PC
beta_canker_results <- data.table(t(sapply(pcs, function(x) beta_canker_anova(x, pc_scores))))

beta_canker_results
```

# Extra figures

## Abundance

```{r}
abundance_combined <- rbind(
  as.data.frame(colData(ubiome_FUN$dds)), as.data.frame(colData(ubiome_BAC$dds))
) %>% mutate(kingdom = ifelse(Target == "ITS", "Fungi", "Bacteria"))

abundance_bar <- ggbarplot(
  data = abundance_combined, x = "Season", y = "log_copy_number", 
  fill = "Site", add = "mean_se", facet.by = "kingdom",
  palette = cbPalette, position = position_dodge(0.8),
  ylab = "Mean copy number (log10)", xlab = F, legend = "right"
) + guides(fill = guide_legend(title = "Site"))

ggsave(
  filename = "abundance_bar.png", plot = abundance_bar, path = "figures/", 
  height = 12, width = 24, units = "cm"
)

abundance_bar
```

## Alpha diversity

```{r}
alpha_combined <- rbind(fun_alpha, bac_alpha) %>% 
  subset(select = c("Site", "Season", "Scion", "Target", "shannon", "simpson")) %>%
  mutate(kingdom = ifelse(Target == "ITS", "Fungi", "Bacteria")) %>%
  pivot_longer(
    cols = c("shannon", "simpson"), names_to = "measure", values_to = "value"
  )

alpha_bar <- ggbarplot(
  data = alpha_combined, x = "Season", y = "value", 
  fill = "Site", add = "mean_se", facet.by = c("measure", "kingdom"), 
  palette = cbPalette, position = position_dodge(0.8), scales = "free_y",
  ylab = "Mean diversity index", xlab = F, legend = "right"
) + guides(fill = guide_legend(title = "Site"))

ggsave(
  filename = "alpha_bar.png", plot = alpha_bar, path = "figures/", 
  height = 12, width = 24, units = "cm"
)

alpha_bar
```

## PCA
  
```{r}
pca_combo_plot <- ggarrange(
  fun_pca_plot, bac_pca_plot,
  ncol = 2, nrow = 1, labels = c("A", "B"),
  common.legend = T, legend = "right"
)

ggsave(
  filename = "pca_combo_plot.png", plot = pca_combo_plot, path = "figures/", 
  height = 18, width = 25, units = "cm"
)

pca_combo_plot

nmds_combo_plot <- ggarrange(
  fun_nmds_plot, bac_nmds_plot,
  ncol = 2, nrow = 1, labels = c("A", "B"),
  common.legend = T, legend = "right"
)

ggsave(
  filename = "nmds_combo_plot.png", plot = nmds_combo_plot, path = "figures/", 
  height = 18, width = 25, units = "cm"
)

nmds_combo_plot

mega_combo_plot <- ggarrange(
  fun_pca_plot, bac_pca_plot,
  fun_nmds_plot, bac_nmds_plot,
  ncol = 2, nrow = 2, labels = c("A", "B", "C", "D"),
  common.legend = T, legend = "bottom"
) + labs(shape = "Planting season")

ggsave(
  filename = "mega_combo_plot.png", plot = mega_combo_plot, path = "figures/", 
  height = 25, width = 30, units = "cm"
)

mega_combo_plot
```